{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 動画とアノテーションデータからBBox付き動画を作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "from PIL import Image, ImageFont, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_labels    = r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\train_annotations\\train_00.json'   \n",
    "path_images    = r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\images\\train_00' \n",
    "\n",
    "classes = ['Car', 'Pedestrian']\n",
    "#classes = ['車', '歩行者']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#for i in range (0, len(annotations)):#here we browse all videos\n",
    "#video_name = annotations[i].split('/')[-1].split('\\\\')[-1].split('.')[0]\n",
    "data       = json.load(open(path_labels))\n",
    "#print(\"\\n\",video_name)\n",
    "\n",
    "#pd_data = pd.DataFrame(data)\n",
    "\n",
    "ids_counter = np.zeros((4, 100000), dtype=int)\n",
    "\n",
    "print(\"len(classes)=\",len(classes))\n",
    "Box_Frame = []\n",
    "for v in range (0,600): #here we browse all frames. Single movie has 600 frames\n",
    "    #img_name     = path_images+'/'+video_name+'/'+str(v)+\".jpg\"\n",
    "    #img = cv.imread(img_name)\n",
    "    BBoxes = []\n",
    "\n",
    "    labels       = data['sequence'][v]\n",
    "    #str_to_write = img_name\n",
    "    for c in range (0, len(classes)):\n",
    "        try:\n",
    "            for inst in data['sequence'][v][classes[c]]:\n",
    "                box           = inst['box2d']\n",
    "\n",
    "                if ((box[2]-box[0])*(box[3]-box[1])) < 900: #we do not want small boxes\n",
    "                    print(\"除外 :v={}, c={}, box[2]-box[0]={}, box[3]-box[1]={}\".format(v,c,box[2]-box[0],box[3]-box[1]))\n",
    "                    continue\n",
    "                \n",
    "                act_id        = inst['id']\n",
    "                id_counter     = ids_counter[c,act_id]\n",
    "                ids_counter[c,act_id] += 1\n",
    "\n",
    "                BBox_Dict = {\n",
    "                    \"class\": c, \n",
    "                    \"id\":act_id, \n",
    "                    \"BBox\":box\n",
    "                    }\n",
    "                \n",
    "                BBoxes.append(BBox_Dict)\n",
    "\n",
    "                #crop = normalize_image_size(img[box[1]:box[3], box[0]:box[2], ...], 224, 224)\n",
    "                #print(\" v={}, c={} :\".format(v,c))\n",
    "                #cv.imwrite(out_dir+'/'+str(c)+'_'+str(i)+'_'+str(act_id)+'_'+str(id_counter)+'_.jpg', crop)\n",
    "                #out_file.write(out_dir+'/'+str(c)+'_'+str(i)+'_'+str(act_id)+'_'+str(id_counter)+'_.jpg\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"v={}, c={} :{}\".format(v,c,e))\n",
    "            continue #nothing, the class is just not presented in the frame\n",
    "            \n",
    "    Box_Frame.append(BBoxes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "hsv_tuples = [(x / len(classes), 1., 1.) for x in range(len(classes))]\n",
    "colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "colors = [(255, 0, 255), (0, 255, 255), (255, 255, 0), (0, 0, 255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(255, 0, 255), (0, 255, 255), (255, 255, 0), (0, 0, 255)]\n"
     ]
    }
   ],
   "source": [
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFont, ImageDraw\n",
    "def detect_image(image, BBox):\n",
    "    start = timer()\n",
    "\n",
    "    #print(\"image.size =\",image.size[1])\n",
    "    size1=np.floor(3e-2 * image.size[1] + 0.5).astype('int32')\n",
    "    #print(\"size1 =\",size1)\n",
    "\n",
    "    font = ImageFont.truetype(font='fonts/arial.ttf', size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    #font = ImageFont.truetype(size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "\n",
    "    for i in range(len(BBox)):\n",
    "    #for i, c in reversed(list(enumerate(out_classes))):\n",
    "        \"\"\"\n",
    "        predicted_class = self.class_names[i]\n",
    "        box = out_boxes[i]\n",
    "        score = out_scores[i]\n",
    "        \"\"\"\n",
    "        class_no = BBox[i][\"class\"]\n",
    "        predicted_class = classes[class_no]\n",
    "        box = BBox[i][\"BBox\"]\n",
    "        #score = out_scores[i]\n",
    "\n",
    "        #label = '{}  id={}'.format(predicted_class, int(BBox[i][\"id\"]))\n",
    "        label = '{}'.format(int(BBox[i][\"id\"]))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        label_size = draw.textsize(label, font)\n",
    "\n",
    "        #top, left, bottom, right = box\n",
    "        left, top, right, bottom = box\n",
    "        #left, bottom, right, top = box\n",
    "        top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "        left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "        bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "        right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "        print(label, (left, top), (right, bottom))\n",
    "\n",
    "        if top - label_size[1] >= 0:\n",
    "            text_origin = np.array([left, top - label_size[1]])\n",
    "        else:\n",
    "            text_origin = np.array([left, top + 1])\n",
    "\n",
    "        # My kingdom for a good redistributable image drawing library.\n",
    "        for i in range(thickness):\n",
    "            draw.rectangle([left + i, top + i, right - i, bottom - i], outline=colors[class_no])\n",
    "\n",
    "        draw.rectangle([tuple(text_origin), tuple(text_origin + label_size)], fill=colors[class_no])\n",
    "        \n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "        del draw\n",
    "\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_video(video_path=\"D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\train_videos\\train_00.mp4\", output_path=r\"D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\out_movie\\base_00.mp4\"):\n",
    "    import cv2\n",
    "    vid = cv2.VideoCapture(video_path)\n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "    video_FourCC    = int(vid.get(cv2.CAP_PROP_FOURCC))\n",
    "    video_fps       = vid.get(cv2.CAP_PROP_FPS)\n",
    "    video_size      = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "                        int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print(\"video_fps={}, video_size={}\".format(video_fps, video_size))\n",
    "    isOutput = True if output_path != \"\" else False\n",
    "    if isOutput:\n",
    "        print(\"!!! TYPE:\", type(output_path), type(video_FourCC), type(video_fps), type(video_size))\n",
    "        out = cv2.VideoWriter(output_path, video_FourCC, video_fps, video_size)\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    for v in range(0,600):\n",
    "        return_value, frame = vid.read()\n",
    "        img_name     = path_images + '/'+str(v)+\".jpg\"\n",
    "        print(\"img_name = \",img_name)\n",
    "        \n",
    "        #image = cv2.imread(img_name)\n",
    "        \n",
    "        #data[v][classes[c]]\n",
    "        image = Image.fromarray(frame)\n",
    "        #image = Image.fromarray(image)\n",
    "        image = detect_image(image, Box_Frame[v])\n",
    "        \n",
    "        result = np.asarray(image)\n",
    "        \n",
    "        curr_time = timer()\n",
    "        exec_time = curr_time - prev_time\n",
    "        prev_time = curr_time\n",
    "        accum_time = accum_time + exec_time\n",
    "        curr_fps = curr_fps + 1\n",
    "        \n",
    "        if accum_time > 1:\n",
    "            accum_time = accum_time - 1\n",
    "            fps = \"FPS: \" + str(curr_fps)\n",
    "            curr_fps = 0\n",
    "        cv2.putText(result, text=\"\", org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.50, color=(255, 0, 0), thickness=1)\n",
    "        cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"result\", result)\n",
    "        if isOutput:\n",
    "            out.write(result)\n",
    "            print(\"write(result)\")\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"break\")\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video(r\"D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\train_videos\\train_00.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo import YOLO, detect_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
