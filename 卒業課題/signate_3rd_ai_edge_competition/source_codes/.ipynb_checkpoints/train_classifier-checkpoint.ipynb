{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_all    = 15\n",
    "epochs_all        = 100\n",
    "imgs_train        = 375787\n",
    "imgs_val          = 19832\n",
    "path_train        = 'train_imgs_class/train'\n",
    "path_val          = 'train_imgs_class/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/yu4u/cutout-random-erasing\n",
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=True):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        if np.random.rand() > p: return input_img\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "            if left + w <= img_w and top + h <= img_h: break\n",
    "        if np.random.rand() >0.5: c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else: c = np.random.uniform(v_l, v_h)\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "        return input_img\n",
    "    return eraser\n",
    "\n",
    "\n",
    "gen_t = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    preprocessing_function=get_random_eraser(),\n",
    ")\n",
    "\n",
    "gen_v = ImageDataGenerator(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_model = efn.EfficientNetB3(weights=None)\n",
    "base_model.layers.pop()\n",
    "base_model.layers.pop()\n",
    "\n",
    "x = Dense(3, activation='softmax')(base_model.layers[-1].output)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[x])\n",
    "\n",
    "#load weights for the second round\n",
    "#model.load_weights('effnet_ep003-loss5.584-val_loss0.001.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def categorical_focal_loss(y_true, y_pred):\n",
    "    gamma=2.\n",
    "    alpha=.25\n",
    "    y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "    epsilon = K.epsilon()\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    cross_entropy = -y_true * K.log(y_pred)\n",
    "    loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "    return K.mean(loss, axis=1)*10000.0 #to avoid 0.0000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for layer in model.layers: layer.trainable = True\n",
    "model.compile(optimizer=Adadelta(0.2), loss=categorical_focal_loss, metrics=['accuracy'])\n",
    "train_generator = gen_t.flow_from_directory(path_train, target_size=(300,300), batch_size=batch_size_all)\n",
    "valid_generator = gen_v.flow_from_directory(path_val,   target_size=(300,300), batch_size=batch_size_all)\n",
    "\n",
    "checkpoint      = ModelCheckpoint('effnet_ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', save_weights_only=True, save_best_only=False,verbose=1)\n",
    "reduce_lr       = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1, delta=0.03)\n",
    "\n",
    "model.fit_generator(train_generator,  steps_per_epoch=3000, epochs=epochs_all, \n",
    "                    validation_data=valid_generator, validation_steps=np.ceil(imgs_val//batch_size_all),\n",
    "                    callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#with this functionality we show boxes with incorect classification. we check them and delete manually boxes\n",
    "#with incorrect classification\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "target_class = 2 #realize for 0, 1, 2\n",
    "bad_imgs = 0\n",
    "dir_imgs_name   = 'C:/Users/Hurtik/python-petr/signate_3rd_ai_edge_competiton/train_imgs_class/train/'+str(target_class)\n",
    "#dir_imgs_name   = 'C:/Users/Hurtik/python-petr/signate_3rd_ai_edge_competiton/train_imgs_class/val/'+str(target_class)\n",
    "list_of_imgs = [root+\"/\"+name\n",
    "             for root, dirs, files in os.walk(dir_imgs_name)\n",
    "             for name in files]    \n",
    "\n",
    "    \n",
    "for im in range (0, len(list_of_imgs), 1):\n",
    "    imgcv = cv.cvtColor(cv.imread(list_of_imgs[im]),cv.COLOR_RGB2BGR)\n",
    "    pred = np.argmax(model.predict(np.expand_dims(imgcv, 0))[0])\n",
    "    if pred != target_class:\n",
    "        print(list_of_imgs[im])\n",
    "        plt.imshow(imgcv)\n",
    "        plt.show()\n",
    "        bad_imgs += 1\n",
    "print('bad_imgs: ', bad_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
