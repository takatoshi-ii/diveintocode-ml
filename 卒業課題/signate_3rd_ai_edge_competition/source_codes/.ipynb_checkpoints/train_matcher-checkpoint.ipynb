{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaDdEayJVxfJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, GlobalAvgPool2D, GlobalMaxPool2D, Input, Flatten, Dense\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import random\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFoUdOBdWeVt"
   },
   "outputs": [],
   "source": [
    "batch_size         = 15\n",
    "matcher_resolution = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpeVPdF6OVpj"
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    _input = Input(shape=input_shape)\n",
    "    base_model = efn.EfficientNetB0(weights=None, include_top=False, input_tensor=_input)\n",
    "    base_model.layers.pop()\n",
    "    base_model.layers.pop()\n",
    "    x = GlobalAvgPool2D()(base_model.layers[-1].output)\n",
    "    return Model(_input, x)\n",
    "\n",
    "input_shape=(matcher_resolution,matcher_resolution,3)\n",
    "base_model= create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "input_c = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_model(input_a)\n",
    "processed_b = base_model(input_b)\n",
    "processed_c = base_model(input_c)\n",
    "\n",
    "concat_v = Concatenate(axis=-1, name='out_concacat')([processed_a, processed_b, processed_c])\n",
    "\n",
    "model = Model([input_a, input_b, input_c], [concat_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbUA3bbtXwIM"
   },
   "outputs": [],
   "source": [
    "with open('data_for_matcher.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open('data_for_matcher_val.txt') as f:\n",
    "    lines_val = f.readlines()\n",
    "\n",
    "num_val = int(len(lines_val))-1\n",
    "num_train = len(lines)-1\n",
    "print('train on', num_train, 'samples;  valid on', num_val, 'samples')\n",
    "\n",
    "\n",
    "\n",
    "def get_random_data(apply_random=True):\n",
    "    x1 = np.empty((batch_size, matcher_resolution, matcher_resolution, 3))\n",
    "    x2 = np.empty((batch_size, matcher_resolution, matcher_resolution, 3))\n",
    "    x3 = np.empty((batch_size, matcher_resolution, matcher_resolution, 3))\n",
    "    \n",
    "    #here load images from line. chose line as randoms\n",
    "    for i in range(0, batch_size):\n",
    "        while True:\n",
    "            if apply_random: #training\n",
    "                index1 = random.randint(0, num_train)\n",
    "                index3 = random.randint(0, num_train)\n",
    "                rec1s = lines[index1].rstrip('\\n')\n",
    "                rec3s = lines[index3].rstrip('\\n')\n",
    "            else: #valid\n",
    "                index1 = random.randint(0, num_val)\n",
    "                index3 = random.randint(0, num_val)\n",
    "                rec1s = lines_val[index1].rstrip('\\n')\n",
    "                rec3s = lines_val[index3].rstrip('\\n')\n",
    "\n",
    "            rec1 = rec1s.split('_')\n",
    "            rec3 = rec3s.split('_')\n",
    "\n",
    "            if rec1[-3] == rec3[-3]: #the same object\n",
    "                continue\n",
    "                \n",
    "            inc = random.randint(1, 6)\n",
    "\n",
    "            rec2 = rec1.copy()\n",
    "            rec2[-2] = str(int(rec2[-2])+inc)\n",
    "            rec2s = \"_\".join(rec2)\n",
    "\n",
    "            if path.exists(rec2s) == False: #we do not have a pair\n",
    "                continue\n",
    "        \n",
    "            \n",
    "            x1[i, ...]  = cv.cvtColor(cv.imread(rec1s), cv.COLOR_BGR2RGB)\n",
    "            x2[i, ...]  = cv.cvtColor(cv.imread(rec2s), cv.COLOR_BGR2RGB)\n",
    "            x3[i, ...]  = cv.cvtColor(cv.imread(rec3s), cv.COLOR_BGR2RGB)\n",
    "            break\n",
    "\n",
    "    y = np.empty((batch_size, 1280*3))\n",
    "\n",
    "    return x1, x2, x3, y\n",
    "\n",
    "\n",
    "\n",
    "def data_generator(is_random):\n",
    "    \"\"\"data generator for fit_generator\"\"\"\n",
    "    while True:\n",
    "        x1, x2, x3, y = get_random_data(apply_random=is_random)    \n",
    "        yield [x1, x2, x3], y\n",
    "\n",
    "\n",
    "def data_generator_wrapper(is_random):\n",
    "    return data_generator(is_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cpj5P9vqR5WI"
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.5):\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "colab_type": "code",
    "id": "eUrzPnnkfzuX",
    "outputId": "a15f3bd0-2cf0-4e29-82f5-413e350208f0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for the second and third round load the best model and reduce lr to half\n",
    "#model = load_model('D:/data-petr/signate_3rd_ai_edge/matcher/matcher_it3.h5', custom_objects={'triplet_loss': triplet_loss})\n",
    "\n",
    "model.compile(optimizer=Adadelta(1.0), loss=triplet_loss)\n",
    "\n",
    "\n",
    "checkpoint      = ModelCheckpoint('D:/data-petr/signate_3rd_ai_edge/matcher/matcher_ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5', monitor='val_loss', save_weights_only=True, save_best_only=False,verbose=1)\n",
    "reduce_lr       = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, delta=0.03)\n",
    "\n",
    "model.fit_generator(data_generator_wrapper(True),\n",
    "                      steps_per_epoch=4000,\n",
    "                      validation_data=data_generator_wrapper(False),\n",
    "                      validation_steps=1000,\n",
    "                      epochs=60,\n",
    "                      callbacks=[reduce_lr, checkpoint])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "matcher.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
