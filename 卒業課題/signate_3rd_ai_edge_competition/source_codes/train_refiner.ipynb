{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import preprocess_input\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "\n",
    "import random\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_all    = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = efn.EfficientNetB3(weights=None)\n",
    "base_model.layers.pop()\n",
    "base_model.layers.pop()\n",
    "\n",
    "x = Dense(4, activation='sigmoid')(base_model.layers[-1].output)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=[x])\n",
    "\n",
    "#for the second and third round load model with the best weights\n",
    "#model.load_weights('D:/data-petr/signate_3rd_ai_edge/refiner/refiner_ep016-loss1.506-val_loss1.223.h5')\n",
    "model.load_weights(r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep003-loss_2.959-val_loss_2.769.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_iou(b1, b2):\n",
    "    #format: batch, x1, y1, x2, y2\n",
    "    b1_mins  = b1[..., 0:2]\n",
    "    b1_maxes = b1[..., 2:4]\n",
    "    b1_wh    = b1_maxes - b1_mins\n",
    "\n",
    "    b2_mins  = b2[..., 0:2]\n",
    "    b2_maxes = b2[..., 2:4]\n",
    "    b2_wh    = b2_maxes - b2_mins\n",
    "\n",
    "\n",
    "    intersect_mins  = K.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh    = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area  = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "    iou = iou+0.00001 #iou is [0,1], so the constant helps to avoid inf\n",
    "\n",
    "    return K.sum(-K.log(iou)) \n",
    "\n",
    "\n",
    "def box_iou_np(b1, b2):\n",
    "    \n",
    "    b1_xy = b1[..., :2]\n",
    "    b1_wh = b1[..., 2:4] - b1_xy\n",
    "    b1_mins = b1_xy\n",
    "    b1_maxes = b1_xy + b1_wh\n",
    "\n",
    "    b2_xy = b2[..., :2]\n",
    "    b2_wh = b2[..., 2:4] - b2_xy\n",
    "    b2_mins = b2_xy\n",
    "    b2_maxes = b2_xy + b2_wh\n",
    "\n",
    "    intersect_mins = np.maximum(b1_mins, b2_mins)\n",
    "    intersect_maxes = np.minimum(b1_maxes, b2_maxes)\n",
    "    intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
    "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
    "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
    "\n",
    "    return 1.0 - (np.sum(iou) / b1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 2303818 samples;  valid on 29425 samples\n"
     ]
    }
   ],
   "source": [
    "with open(r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\data_for_refiner_training.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "with open(r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\data_for_refiner_validation.txt') as f:\n",
    "    lines_val = f.readlines()\n",
    "\n",
    "num_val = int(len(lines_val))\n",
    "num_train = len(lines)\n",
    "print('train on', num_train, 'samples;  valid on', num_val, 'samples')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_random_data(annotation_line, apply_random=True):\n",
    "    line = annotation_line.split()\n",
    "\n",
    "    image = cv.cvtColor(cv.imread(line[0]), cv.COLOR_BGR2RGB)\n",
    "    box = np.array([np.array(list(map(float, box.split(',')))) for box in line[1:]])\n",
    "\n",
    "    if apply_random == False:  \n",
    "        return image, [box[0][0], box[0][1], box[0][2], box[0][3]]\n",
    "\n",
    "    hue=20\n",
    "    sat=40 \n",
    "    val=50\n",
    "    \n",
    "    if random.random() < .2:\n",
    "        clahe = cv.createCLAHE(clipLimit=2, tileGridSize=(8,8))\n",
    "        lab = cv.cvtColor(image, cv.COLOR_RGB2LAB)\n",
    "        l, a, b = cv.split(lab)\n",
    "        cl = clahe.apply(l)\n",
    "        limg = cv.merge((cl,a,b))\n",
    "        image = cv.cvtColor(limg, cv.COLOR_LAB2RGB)\n",
    "        \n",
    "    #shift   \n",
    "    new_image = np.full((300,300,3), 0, dtype='uint8')\n",
    "    sx = random.randint(-30, 40)\n",
    "    sy = random.randint(-30, 40)\n",
    "    sx_float = sx/300.0\n",
    "    sy_float = sy/300.0\n",
    "    new_image[max(0, sy):min(300, 300+sy), max(0, sx):min(300, 300+sx), ...] = image[max(0, -sy):min(300, 300-sy), max(0,-sx):min(300, 300-sx), ...]\n",
    "    image = new_image\n",
    "    box[0][0] = max(min(box[0][0] + sx_float, 1.0), 0.0)\n",
    "    box[0][1] = max(min(box[0][1] + sy_float, 1.0), 0.0)\n",
    "    box[0][2] = max(min(box[0][2] + sx_float, 1.0), 0.0)\n",
    "    box[0][3] = max(min(box[0][3] + sy_float, 1.0), 0.0)\n",
    "\n",
    "\n",
    "    #flip image or not\n",
    "    flip = random.random() < .5\n",
    "    if flip:  image = cv.flip(image, 1)\n",
    "\n",
    "    # distort image\n",
    "    hsv = np.int32(cv.cvtColor(image, cv.COLOR_RGB2HSV))\n",
    "    \n",
    "    #linear hsv distortion\n",
    "    hsv[..., 0] += random.randint(-hue, hue)\n",
    "    hsv[..., 1] += random.randint(-sat, sat)\n",
    "    hsv[..., 2] += random.randint(-val, val)\n",
    "    \n",
    "    #additional non-linear distortion of saturation and value\n",
    "    if random.random()<0.4:\n",
    "        hsv[..., 1] = hsv[..., 1]*random.uniform(.5, 1.5)\n",
    "        hsv[..., 2] = hsv[..., 2]*random.uniform(.5, 1.5)\n",
    "        \n",
    "    hsv[..., 0][hsv[..., 0] > 179] = 179\n",
    "    hsv[..., 0][hsv[..., 0] < 0]   = 0\n",
    "    hsv[..., 1][hsv[..., 1] > 255] = 255\n",
    "    hsv[..., 1][hsv[..., 1] < 0]   = 0\n",
    "    hsv[..., 2][hsv[..., 2] > 255] = 255\n",
    "    hsv[..., 2][hsv[..., 2] < 0]   = 0\n",
    "    \n",
    "    image = cv.cvtColor(np.uint8(hsv), cv.COLOR_HSV2RGB)\n",
    "\n",
    "\n",
    "    box_data = np.zeros((1, 4))\n",
    "    if len(box) > 0:\n",
    "        box[:, [0, 2]] = box[:, [0, 2]]\n",
    "        box[:, [1, 3]] = box[:, [1, 3]]\n",
    "        if flip: box[:, [0, 2]] = 1.0 - box[:, [2, 0]]\n",
    "            \n",
    "    return image, [box[0][0], box[0][1], box[0][2], box[0][3]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, is_random):\n",
    "    \"\"\"data generator for fit_generator\"\"\"\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i == 0: np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], apply_random=is_random)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        y_true = np.array(box_data)\n",
    "        yield image_data, y_true\n",
    "\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, random):\n",
    "    n = len(annotation_lines)\n",
    "    if n == 0 or batch_size <= 0: return None\n",
    "    return data_generator(annotation_lines, batch_size, random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Takatoshi\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Takatoshi\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Takatoshi\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Takatoshi\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Takatoshi\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 912s 912ms/step - loss: 2.7339 - val_loss: 2.0510\n",
      "\n",
      "Epoch 00001: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep001-loss_2.734-val_loss_2.051.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 886s 886ms/step - loss: 2.5561 - val_loss: 1.8424\n",
      "\n",
      "Epoch 00002: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep002-loss_2.556-val_loss_1.842.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 892s 892ms/step - loss: 2.4066 - val_loss: 2.0305\n",
      "\n",
      "Epoch 00003: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep003-loss_2.407-val_loss_2.031.h5\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 893s 893ms/step - loss: 2.3238 - val_loss: 2.4732\n",
      "\n",
      "Epoch 00004: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep004-loss_2.324-val_loss_2.473.h5\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 891s 891ms/step - loss: 2.2246 - val_loss: 1.7708\n",
      "\n",
      "Epoch 00005: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep005-loss_2.225-val_loss_1.771.h5\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 886s 886ms/step - loss: 2.1546 - val_loss: 1.7862\n",
      "\n",
      "Epoch 00006: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep006-loss_2.155-val_loss_1.786.h5\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 876s 876ms/step - loss: 2.1208 - val_loss: 2.2102\n",
      "\n",
      "Epoch 00007: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep007-loss_2.121-val_loss_2.210.h5\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 877s 877ms/step - loss: 2.0451 - val_loss: 2.3450\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.5.\n",
      "\n",
      "Epoch 00008: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep008-loss_2.045-val_loss_2.345.h5\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 876s 876ms/step - loss: 1.8243 - val_loss: 1.7799\n",
      "\n",
      "Epoch 00009: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep009-loss_1.824-val_loss_1.780.h5\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 877s 877ms/step - loss: 1.8075 - val_loss: 1.8120\n",
      "\n",
      "Epoch 00010: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep010-loss_1.807-val_loss_1.812.h5\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 880s 880ms/step - loss: 1.7367 - val_loss: 1.8084\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.25.\n",
      "\n",
      "Epoch 00011: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep011-loss_1.737-val_loss_1.808.h5\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 878s 878ms/step - loss: 1.6767 - val_loss: 1.4913\n",
      "\n",
      "Epoch 00012: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep012-loss_1.677-val_loss_1.491.h5\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 876s 876ms/step - loss: 1.6337 - val_loss: 1.5887\n",
      "\n",
      "Epoch 00013: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep013-loss_1.634-val_loss_1.589.h5\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 880s 880ms/step - loss: 1.5762 - val_loss: 1.5896\n",
      "\n",
      "Epoch 00014: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep014-loss_1.576-val_loss_1.590.h5\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 895s 895ms/step - loss: 1.5844 - val_loss: 1.4602\n",
      "\n",
      "Epoch 00015: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep015-loss_1.584-val_loss_1.460.h5\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 892s 892ms/step - loss: 1.5697 - val_loss: 1.4887\n",
      "\n",
      "Epoch 00016: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep016-loss_1.570-val_loss_1.489.h5\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 890s 890ms/step - loss: 1.5482 - val_loss: 1.4428\n",
      "\n",
      "Epoch 00017: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep017-loss_1.548-val_loss_1.443.h5\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 898s 898ms/step - loss: 1.5138 - val_loss: 1.4881\n",
      "\n",
      "Epoch 00018: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep018-loss_1.514-val_loss_1.488.h5\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 905s 905ms/step - loss: 1.5051 - val_loss: 1.4521\n",
      "\n",
      "Epoch 00019: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep019-loss_1.505-val_loss_1.452.h5\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 898s 898ms/step - loss: 1.4995 - val_loss: 1.5110\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.125.\n",
      "\n",
      "Epoch 00020: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep020-loss_1.500-val_loss_1.511.h5\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 926s 926ms/step - loss: 1.4555 - val_loss: 1.4273\n",
      "\n",
      "Epoch 00021: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep021-loss_1.456-val_loss_1.427.h5\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 920s 920ms/step - loss: 1.4345 - val_loss: 1.3492\n",
      "\n",
      "Epoch 00022: saving model to D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep022-loss_1.435-val_loss_1.349.h5\n",
      "Epoch 23/50\n",
      "  82/1000 [=>............................] - ETA: 6:30 - loss: 1.4843"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-52a8769b324c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_val\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                       callbacks=[reduce_lr, checkpoint])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=Adadelta(1.0), loss=box_iou)\n",
    "\n",
    "\n",
    "checkpoint      = ModelCheckpoint(r'D:\\SIGNATE\\Signate_3rd_AI_edge_competition\\refiner_model/refiner_ep{epoch:03d}-loss_{loss:.3f}-val_loss_{val_loss:.3f}.h5', monitor='val_loss', save_weights_only=True, save_best_only=False,verbose=1)\n",
    "reduce_lr       = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, delta=0.03)\n",
    "\n",
    "\n",
    "model.fit_generator(data_generator_wrapper(lines, batch_size_all, True),\n",
    "                      steps_per_epoch=1000,\n",
    "                      validation_data=data_generator_wrapper(lines_val, batch_size_all, False),\n",
    "                      validation_steps=max(1, num_val // batch_size_all),\n",
    "                      epochs=50,\n",
    "                      callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
