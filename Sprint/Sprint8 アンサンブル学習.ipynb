{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint アンサンブル学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.このSprintについて"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprintの目的  \n",
    "・アンサンブル学習について理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どのように学ぶか  \n",
    "・スクラッチでアンサンブル学習の各種手法を実装していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.アンサンブル学習  \n",
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。  \n",
    "・ブレンディング  \n",
    "・バギング  \n",
    "・スタッキング  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。  \n",
    "House Prices: Advanced Regression Techniques  \n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。  \n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation  \n",
    "sklearn.svm.SVR — scikit-learn 0.21.3 documentation  \n",
    "sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.ブレンディング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディングのスクラッチ実装  \n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ブレンディングとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。  \n",
    "最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）  \n",
    "ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）  \n",
    "入力データの前処理の仕方（例：標準化、対数変換、PCAなど）  \n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。  \n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。  \n",
    "\n",
    "《補足》  \n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./HousePrice_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df = df\n",
    "# 半分以上欠損値を含む列を削除する。\n",
    "drop_df = drop_df.dropna(thresh=df.shape[0]*0.5, axis=1)\n",
    "\n",
    "# 欠損値があるサンプル（行）は削除する。\n",
    "drop_df = drop_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>2004</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2090</td>\n",
       "      <td>1995</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1578</td>\n",
       "      <td>2008</td>\n",
       "      <td>287090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>1999</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>1978</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>1941</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>583 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt  SalePrice\n",
       "1          1262       1976     181500\n",
       "2          1786       2001     223500\n",
       "3          1717       1915     140000\n",
       "4          2198       2000     250000\n",
       "6          1694       2004     307000\n",
       "...         ...        ...        ...\n",
       "1447       2090       1995     240000\n",
       "1451       1578       2008     287090\n",
       "1455       1647       1999     175000\n",
       "1456       2073       1978     210000\n",
       "1457       2340       1941     266500\n",
       "\n",
       "[583 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = drop_df.loc[:,[\"GrLivArea\",\"YearBuilt\",\"SalePrice\"]]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# ndarrayへ変換\n",
    "X = np.array(df_data.iloc[:,0:2])\n",
    "y = np.array(df_data.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データと検証データの分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_splitを実行するたびに、X_train, X_test, y_train, y_testが変動するためMSEスコアが変動するため保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"X_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "\n",
    "with open(\"X_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test, f)\n",
    "    \n",
    "with open(\"y_train.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_train, f)\n",
    "    \n",
    "with open(\"y_test.pkl\", \"wb\") as f:\n",
    "    pickle.dump(y_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "ss_X_train = ss.transform(X_train)\n",
    "ss_X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類器をセット。ここではロジスティック回帰、ランダムフォレスト分類器、ガウシアンナイーブベースを用いる。\n",
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = SVC(probability=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単一モデルで検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ＜ロジスティック回帰＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5321997491.7260275"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "ss_clf = clf1.fit(ss_X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "y_pred_LR = clf1.predict(ss_X_test)\n",
    "\n",
    "# 評価\n",
    "err_LR = mean_squared_error(y_test, y_pred_LR)\n",
    "err_LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ＜ランダムフォレスト＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4414022744.479452"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "ss_clf = clf2.fit(ss_X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "y_pred_LF = clf2.predict(ss_X_test)\n",
    "\n",
    "# 評価\n",
    "err_LR = mean_squared_error(y_test, y_pred_LF)\n",
    "err_LR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ＜ガウシアンナイーブベース＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4824000759.534246"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "ss_clf = clf3.fit(ss_X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "y_pred_GNB = clf3.predict(ss_X_test)\n",
    "\n",
    "# 評価\n",
    "err_GNB = mean_squared_error(y_test, y_pred_GNB)\n",
    "err_GNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ＜SVC＞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5800495447.20548"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習\n",
    "clf = clf4.fit(ss_X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "y_pred_SVM = clf4.predict(ss_X_test)\n",
    "\n",
    "# 評価\n",
    "err_svc = mean_squared_error(y_test, y_pred_SVM)\n",
    "err_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アンサンブルモデルで検証"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <voting='hard'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#アンサンブル学習器を作成。voting='hard'に設定し、単純な多数決で値を決めることにする。\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(ss_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([170000, 270000, 118000, 208900, 160200, 174000, 230000, 250000,\n",
       "       225000, 236000, 176000, 170000, 170000, 230000, 183500, 250000,\n",
       "       250000, 250000, 219500, 275000, 170000, 174000, 133900, 140000,\n",
       "       174000,  91500, 140000, 290000, 140000, 119000, 142000, 159000,\n",
       "       240000, 174000, 140000, 170000, 250000, 220000, 143000, 250000,\n",
       "       184750, 230000, 125000, 174000, 123000, 191000, 135000, 174000,\n",
       "       119000, 144500, 140000, 140000, 174000, 176000, 174000, 214000,\n",
       "       250000, 240000, 120000, 135000,  62383, 250000, 134000, 250000,\n",
       "       176000, 230000, 151000, 174000, 174000, 290000, 178000, 192140,\n",
       "       174000, 230000, 174000, 174000, 140000, 174000, 134000, 250000,\n",
       "       250000, 250000, 240000, 170000, 183500, 176000, 230000, 230000,\n",
       "       189000, 120000, 120000, 250000, 174000, 295000, 143000, 250000,\n",
       "       250000, 170000, 225000, 190000, 230000, 140000, 170000, 170000,\n",
       "       215000, 190000, 170000, 176000, 176000, 140000, 222500, 149500,\n",
       "       135000, 170000, 170000, 120000, 232000, 250000, 140000, 146500,\n",
       "       240000, 191000, 220000, 189000, 250000, 239000, 230000, 155000,\n",
       "       250000, 123000, 174000, 174000, 250000,  91000, 250000, 174000,\n",
       "       176000, 174000, 149500, 170000, 250000, 140000, 170000, 117000,\n",
       "       174000, 120000], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = eclf1.predict(ss_X_test)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
    "               eclf1.named_estimators_['lr'].predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5677414021.102739"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err1 = mean_squared_error(y_test, y_pred1)\n",
    "err1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <voting='soft'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "eclf2 = eclf2.fit(ss_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196500, 270000, 120000, 208900, 192000, 244600, 306000, 271900,\n",
       "       225000, 240000, 197000, 280000, 167500, 232000, 183500, 325300,\n",
       "       250000, 340000, 219500, 275000, 181000, 279500, 185000, 157500,\n",
       "       180000, 113000, 161000, 446261, 174500, 132000, 143000, 159000,\n",
       "       265979, 207000, 177000, 239000, 380000, 311872, 179900, 225000,\n",
       "       320000, 219210, 125000, 174000, 143000, 239000, 155000, 192000,\n",
       "       119000, 144500, 144000, 180500, 192000, 208900, 181000, 214000,\n",
       "       250000, 240000, 120000, 257500,  62383, 250000, 160000, 275500,\n",
       "       230000, 392500, 181000, 192000, 245000, 290000, 178000, 275000,\n",
       "       208900, 281000, 181000, 286000, 165000, 174000, 134000, 250000,\n",
       "       269790, 285000, 266500, 172500, 183500, 187750, 281000, 237000,\n",
       "       210000, 120000, 143000, 336000, 192000, 295000, 143000, 501837,\n",
       "       250000, 170000, 225000, 190000, 231500, 146500, 176000, 170000,\n",
       "       241500, 190000, 175000, 187750, 230000, 160000, 222500, 176000,\n",
       "       155000, 217500, 280000, 120000, 232000, 402861, 174500, 146500,\n",
       "       239000, 239000, 311872, 220000, 501837, 239000, 233230, 155000,\n",
       "       325624, 123000, 208900, 279500, 378500, 120000, 275000, 175900,\n",
       "       187750, 220000, 175000, 170000, 325000, 177000, 280000, 144000,\n",
       "       315500, 120000], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = eclf2.predict(ss_X_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3741653515.712329"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err2 = mean_squared_error(y_test, y_pred2)\n",
    "err2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf21 = VotingClassifier(estimators=[('rf', clf2), ('gnb', clf3), ('svc', clf4)], voting='soft')\n",
    "eclf21 = eclf21.fit(ss_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196500, 270000, 120000, 208900, 192000, 244600, 306000, 271900,\n",
       "       225000, 236000, 197000, 280000, 167500, 232000, 183500, 325300,\n",
       "       250000, 340000, 219500, 275000, 181000, 279500, 185000, 157500,\n",
       "       180000, 113000, 161000, 446261, 174500, 132000, 143000, 159000,\n",
       "       265979, 207000, 177000, 239000, 380000, 311872, 179900, 225000,\n",
       "       320000, 219210, 125000, 174000, 143000, 239000, 155000, 192000,\n",
       "       119000, 144500, 144000, 180500, 192000, 208900, 181000, 214000,\n",
       "       250000, 240000, 120000, 257500,  62383, 250000, 160000, 275500,\n",
       "       230000, 392500, 181000, 192000, 245000, 290000, 178000, 275000,\n",
       "       208900, 281000, 181000, 286000, 165000, 174000, 134000, 250000,\n",
       "       269790, 285000, 266500, 172500, 183500, 187750, 281000, 237000,\n",
       "       210000, 120000, 143000, 336000, 192000, 191000, 143000, 501837,\n",
       "       250000, 170000, 225000, 190000, 231500, 146500, 176000, 170000,\n",
       "       241500, 190000, 175000, 187750, 230000, 160000, 222500, 176000,\n",
       "       155000, 217500, 280000, 120000, 232000, 402861, 174500, 146500,\n",
       "       239000, 239000, 311872, 220000, 501837, 239000, 233230, 155000,\n",
       "       325624, 123000, 208900, 279500, 378500, 120000, 275000, 175900,\n",
       "       187750, 220000, 175000, 170000, 325000, 177000, 280000, 144000,\n",
       "       315500, 120000], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred21 = eclf21.predict(ss_X_test)\n",
    "y_pred21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071626118.452055"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err21 = mean_squared_error(y_test, y_pred21)\n",
    "err21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 同一モデルのハイパーパラメータ違いを複数組み合わせてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf22 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf23 = RandomForestClassifier(n_estimators=80, random_state=2)\n",
    "clf24 = RandomForestClassifier(n_estimators=100, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf22 = VotingClassifier(estimators=[('rf1', clf22), ('rf2', clf23), ('rf3', clf24)], voting='soft')\n",
    "eclf22 = eclf22.fit(ss_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred22 = eclf21.predict(ss_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071626118.452055"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err22 = mean_squared_error(y_test, y_pred22)\n",
    "err22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf25 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf26 = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "clf27 = RandomForestClassifier(n_estimators=50, random_state=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf23 = VotingClassifier(estimators=[('rf1', clf25), ('rf2', clf26), ('rf3', clf27)], voting='soft')\n",
    "eclf23 = eclf23.fit(ss_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred23 = eclf23.predict(ss_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4775140491.739726"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err23 = mean_squared_error(y_test, y_pred23)\n",
    "err23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <voting='soft', with weight>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰はMSEが大きいので除外し、  \n",
    "②ランダムフォレスト  \n",
    "③ガウシアンナイーブベース  \n",
    "④SVM  \n",
    "の３つで、ウェイトを1：2：1とし、一番単体精度の高いガウシアンナイーブベース の比率を２とする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf3 = VotingClassifier(estimators=[('rf', clf2), ('gnb', clf3), ('svc', clf4)], voting='soft', weights=[1,2,1], flatten_transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf3 = eclf3.fit(ss_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196500, 270000, 120000, 208900, 192000, 244600, 306000, 271900,\n",
       "       290000, 350000, 176000, 280000, 167500, 232000, 275000, 325300,\n",
       "       230000, 340000, 230000, 275000, 181000, 279500, 185000, 185000,\n",
       "       270000, 170000, 161000, 320000, 174500, 132000, 143000, 159000,\n",
       "       240000, 208900, 177000, 239000, 325000, 311872, 179900, 225000,\n",
       "       320000, 219210, 134000, 232000, 143000, 239000, 155000, 192000,\n",
       "       119000, 175000, 144000, 180500, 192000, 208900, 181000, 214000,\n",
       "       250000, 240000, 120000, 257500, 143000, 230000, 160000, 275500,\n",
       "       230000, 392500, 181000, 192000, 245000, 290000, 178000, 275000,\n",
       "       208900, 281000, 181000, 270000, 165000, 232000, 134000, 250000,\n",
       "       240000, 315000, 266500, 172500, 275000, 176000, 281000, 230000,\n",
       "       210000, 120000, 143000, 290000, 192000, 191000, 143000, 350000,\n",
       "       250000, 170000, 225000, 190000, 231500, 140000, 176000, 170000,\n",
       "       241500, 190000, 179900, 187750, 230000, 185000, 230000, 176000,\n",
       "       155000, 171000, 280000, 151000, 232000, 402861, 140000, 159000,\n",
       "       240000, 191000, 311872, 220000, 501837, 239000, 233230, 179900,\n",
       "       325000, 143000, 208900, 208900, 378500, 120000, 275000, 175900,\n",
       "       208900, 220000, 175000, 170000, 290000, 177000, 280000, 144000,\n",
       "       193000, 120000], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = eclf3.predict(ss_X_test)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4136419091.9452057"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err3 = mean_squared_error(y_test, y_pred3)\n",
    "err3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上の結果から\n",
    "\n",
    "\n",
    "|       | 単体モデル                | MSE               |\n",
    "|-------|---------------------------|-------------------|\n",
    "| Base1 | ①ロジスティック回帰       | 5321997491.726020 |\n",
    "| Base2 | ②ランダムフォレスト       | 4414022744.479450 |\n",
    "| Base3 | ③ガウシアンナイーブベース | 4824000759.534240 |\n",
    "| Base4 | ④SVC                      | 5800495447.205480 |\n",
    "\n",
    "\n",
    "|           | アンサンブルモデル               |                   |   |\n",
    "|-----------|----------------------------------|-------------------|---|\n",
    "| ensemble1 | ①+②+③：head：                    | 5677414021.102730 |   |\n",
    "| ensemble2 | ①+②+③：soft：                    | 3741653515.712320 | ★ |\n",
    "| ensemble3 | ②+③+④：soft：                    | 4071626118.452050 | ★ |\n",
    "| ensemble4 | ②+②+②：soft：                    | 4775140491.739720 | 　 |\n",
    "| ensemble5 | ②+③+④：soft：waights   = [1,2,1] | 4136419091.945200 | ★ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ⅰ)ensemble2で「ロジスティック回帰」+「ランダムフォレスト」+「ガウシアンナイーブベース」の組み合わせでは、  \n",
    "soft(予測確率のargmax）で3741653515.712320\t \n",
    "となり、各単体モデルのスコアより高い精度を示している。 \n",
    "\n",
    "(ⅱ)ensemble3で「ランダムフォレスト」+「ガウシアンナイーブベース」+「SVC」の組み合わせでは、  \n",
    "soft(予測確率のargmax）で4071626118.452050\t \n",
    "となり、各単体モデルのスコアより高い精度を示している。\n",
    "\n",
    "(ⅲ)ensemble5で「ランダムフォレスト」+「ガウシアンナイーブベース」+「SVC」の組み合わせでは、  \n",
    "比率を1：2：1とすることで、\n",
    "soft(予測確率のargmax）で4136419091.945200\t \n",
    "となり、各単体モデルのスコアより高い精度を示している。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.バギング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "ss_X = ss.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "befor delete y_pred.shape = (146, 6)\n",
      "after delete y_pred.shape = (146, 5)\n",
      "y_pred_DT.shape = (146, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6298982658.290137"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 決定木\n",
    "model_DT = DecisionTreeClassifier()\n",
    "\n",
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(ss_X, y, test_size=0.25, shuffle = True)\n",
    "\n",
    "# 空行列作成\n",
    "y_test_bag.reshape(-1,1)\n",
    "y_pred = np.zeros((y_test_bag.shape[0], 1))\n",
    "\n",
    "n_iter = 5\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # 分割\n",
    "    X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(ss_X, y, test_size=0.25, shuffle = True)\n",
    "\n",
    "    # 学習\n",
    "    clf = model_DT.fit(X_train_bag, y_train_bag)\n",
    "\n",
    "    # 推定\n",
    "    y_pred_WK = model_DT.predict(X_test_bag).reshape(-1,1)\n",
    "\n",
    "    # predict arrayに追加\n",
    "    y_pred = np.concatenate([y_pred, y_pred_WK], axis = 1)\n",
    "\n",
    "print(\"befor delete y_pred.shape = {}\".format(y_pred.shape))\n",
    "y_pred = np.delete(y_pred, 0, axis = 1)\n",
    "print(\"after delete y_pred.shape = {}\".format(y_pred.shape))\n",
    "    \n",
    "# 推定結果の平均\n",
    "y_pred_DT = np.mean(y_pred, axis = 1).reshape(-1,1)\n",
    "print(\"y_pred_DT.shape = {}\".format(y_pred_DT.shape))\n",
    "\n",
    "# 評価\n",
    "err_DT = mean_squared_error(y_test, y_pred_DT)\n",
    "err_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_DT.shape = (146, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "959581835.839452"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "## ガウシアンナイーブベース\n",
    "GNB = GaussianNB()\n",
    "\n",
    "# 標準化\n",
    "ss = StandardScaler()\n",
    "ss.fit(X)\n",
    "ss_X = ss.transform(X)\n",
    "\n",
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(ss_X, y, test_size=0.25, shuffle = True)\n",
    "\n",
    "# 空行列作成\n",
    "y_test_bag.reshape(-1,1)\n",
    "y_pred = np.zeros((y_test_bag.shape[0], 1))\n",
    "y_true = np.zeros((y_test_bag.shape[0], 1))\n",
    "\n",
    "\n",
    "n_iter = 5\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # 分割\n",
    "    X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(ss_X, y, test_size=0.25, shuffle = True)\n",
    "\n",
    "    # 学習\n",
    "    GNB.fit(X_train_bag, y_train_bag)\n",
    "\n",
    "    # 推定\n",
    "    y_pred_WK = GNB.predict(X_test_bag).reshape(-1,1)\n",
    "    y_test_bag = y_test_bag.reshape(-1,1)\n",
    "    \n",
    "    y_pred = np.concatenate([y_pred, y_pred_WK], axis = 1)\n",
    "    y_true = np.concatenate([y_true, y_test_bag], axis = 1)\n",
    "\n",
    "# 正解データ、予測データの最初の列はダミーデータが入っているので削除する。\n",
    "y_pred = np.delete(y_pred, 0, axis = 1)\n",
    "y_true = np.delete(y_true, 0, axis = 1)\n",
    "\n",
    "    \n",
    "# 正解データ、推定結果の平均\n",
    "y_pred_DT = np.mean(y_pred, axis = 1).reshape(-1,1)\n",
    "y_true = np.mean(y_true, axis = 1).reshape(-1,1)\n",
    "print(\"y_pred_DT.shape = {}\".format(y_pred_DT.shape))\n",
    "\n",
    "# 評価\n",
    "err_GNB = mean_squared_error(y_true, y_pred_DT)\n",
    "err_GNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上をまとめると\n",
    "\n",
    "| 単一モデル                |                   |\n",
    "|---------------------------|-------------------|\n",
    "| モデル                    | MSE               |\n",
    "| ③ガウシアンナイーブベース | 6298982658.290137 |\n",
    "\n",
    "\n",
    "| アンサンブル(バギング)    |                   |\n",
    "|---------------------------|-------------------|\n",
    "| モデル                    | MSE               |\n",
    "| ③ガウシアンナイーブベース | 959581835.839452 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 以上の結果となり、ガウシアンナイーブベースの単体のMSEが6298982658.290137であるのに対して、  \n",
    "バギングを行った後のMSEは、959581835.839452となり、6倍以上の精度向上が見られた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.スタッキング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スタッキングとは"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。  \n",
    "まずは \n",
    "$K_0$= 3, $M_0$= 2\n",
    " 程度にします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 《学習時》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ 0 ）\n",
    "\n",
    "・学習データを $K_0$個に分割する。  \n",
    "・分割した内の ($K_0$ − 1) 個をまとめて学習用データ、残り 1個を推定用データとする組み合わせが $K_0$ 個作れる。  \n",
    "・あるモデルのインスタンスを $K_0$ 個用意し、異なる学習用データを使い学習する。  \n",
    "・それぞれの学習済みモデルに対して、使っていない残り 1 個の推定用データを入力し、推定値を得る。  \n",
    "（これをブレンドデータと呼ぶ）  \n",
    "・さらに、異なるモデルのインスタンスも $K_0$ 個用意し、同様のことを行う。モデルが $M_0$ 個あれば、   \n",
    "$M_0$ 個のブレンドデータが得られる。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ n ）\n",
    "\n",
    "・ステージ n − 1 のブレンドデータを $M_n−1$ 次元の特徴量を持つ学習用データと考え、 $K_n$ 個に分割する。  \n",
    "以下同様である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ N ）＊最後のステージ\n",
    "\n",
    "・ステージ N − 1 の $M_{N−1}$ 個のブレンドデータを$M_{N−1}$ 次元の特徴量の入力として、  \n",
    "1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 《推定時》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ 0 ）\n",
    "\n",
    "・テストデータを \n",
    "$K_0$ × $M_0$ 個の学習済みモデルに入力し、$K_0$ × $M_0$ 個の推定値を得る。  \n",
    "これを $K_0$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ n ）\n",
    "\n",
    "・ステージ n−1 で得たブレンドテストを $K_n$ × $M_n$ 個の学習済みモデルに入力し、$K_n$ × $M_n$ 個の推定値を得る。  \n",
    "これを $K_n$ の軸で平均値を求め $M_0$ 次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（ステージ N ）＊最後のステージ\n",
    "\n",
    "・ステージ N − 1 で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《学習時》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i =  0\n",
      "X_train.shape = (388, 2)\n",
      "X_test.shape = (388, 2)\n",
      "y_train.shape = (388,)\n",
      "y_test.shape = (195,)\n",
      "i =  1\n",
      "X_train.shape = (389, 2)\n",
      "X_test.shape = (389, 2)\n",
      "y_train.shape = (389,)\n",
      "y_test.shape = (194,)\n",
      "i =  2\n",
      "X_train.shape = (389, 2)\n",
      "X_test.shape = (389, 2)\n",
      "y_train.shape = (389,)\n",
      "y_test.shape = (194,)\n",
      "★★★y_brend = \n",
      "[[157000. 152000.]\n",
      " [255000. 186500.]\n",
      " [144000. 155000.]\n",
      " ...\n",
      " [270000. 328900.]\n",
      " [250000. 192000.]\n",
      " [240000. 259500.]]\n",
      "★★★y_brend.shape = (583, 2)\n",
      "y_brend_fin.shape =  (583, 1)\n"
     ]
    }
   ],
   "source": [
    "# クロスバリデーション\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X_train_list = []\n",
    "X_test_list = []\n",
    "y_train_list = []\n",
    "y_test_list = []\n",
    "model_ins = []\n",
    "i = 0\n",
    "y_brend1 = None\n",
    "y_brend2 = None\n",
    "y_brend3 = None\n",
    "y_brend4 = None\n",
    "\n",
    "model_ins1 = []\n",
    "model_ins2 = []\n",
    "\n",
    "\n",
    "# << stage 0 >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "\n",
    "# 分割数\n",
    "K0= 3\n",
    "\n",
    "# モデル数\n",
    "M0 = 2\n",
    "\n",
    "# クロスバリデーション\n",
    "kf = KFold(n_splits = K0)\n",
    "kf.get_n_splits(ss_X)\n",
    "\n",
    "# 変数初期化\n",
    "y_brend = np.zeros(ss_X.shape[0] * M0).reshape(ss_X.shape[0], M0).reshape(-1, M0)\n",
    "model_ins_0 = np.empty(K0 * M0).reshape(K0, M0)\n",
    "model_ins_0 = model_ins_0.astype(np.object)\n",
    "\n",
    "# インスタンス作成\n",
    "for ins in range(K0):\n",
    "    \n",
    "    model_ins_0[ins,0] = GaussianNB()\n",
    "    model_ins_0[ins,1] = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "\n",
    "# データ分割\n",
    "for i, (train_index, test_index) in enumerate(kf.split(ss_X)):\n",
    "    print(\"i = \", i)\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "        \n",
    "    X_train, X_test = ss_X[train_index], ss_X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "    print(\"X_train.shape = {}\".format(X_train.shape))\n",
    "    print(\"X_test.shape = {}\".format(X_train.shape))\n",
    "    print(\"y_train.shape = {}\".format(y_train.shape))\n",
    "    print(\"y_test.shape = {}\".format(y_test.shape))\n",
    "    \n",
    "    \n",
    "    for j in range(M0):\n",
    "        # 学習\n",
    "        model_ins_0[i,j].fit(X_train, y_train)\n",
    "\n",
    "        # 推定\n",
    "        y_brend[test_index, j] = model_ins_0[i,j].predict(X_test).flatten()\n",
    "    \n",
    "print(\"★★★y_brend = \\n{}\".format(y_brend))\n",
    "print(\"★★★y_brend.shape = {}\".format(y_brend.shape))\n",
    "\n",
    "\n",
    "# << stage n >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "Kn = 3\n",
    "Mn = 2\n",
    "n_cnt = 1\n",
    "kf = KFold(n_splits = Kn)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# 変数初期化\n",
    "model_ins_n = np.empty(Kn * Mn).reshape(Kn, Mn)\n",
    "model_ins_n = model_ins_n.astype(np.object)\n",
    "\n",
    "\n",
    "# インスタンス作成\n",
    "for ins in range(K0):\n",
    "    \n",
    "    model_ins_n[ins,0] = GaussianNB()\n",
    "    model_ins_n[ins,1] = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "# n回ループ\n",
    "for n in range(n_cnt):\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(y_brend)):\n",
    "\n",
    "        X_train, X_test = y_brend[train_index], y_brend[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train_list.append(X_train)\n",
    "        X_test_list.append(X_test)\n",
    "        y_train_list.append(y_train)\n",
    "        y_test_list.append(y_test)\n",
    "\n",
    "\n",
    "        for j in range(Mn):\n",
    "            # 学習\n",
    "            model_ins_n[i,j].fit(X_train, y_train)\n",
    "\n",
    "            # 推定\n",
    "            y_brend[test_index, j] = model_ins_n[i,j].predict(X_test).flatten()\n",
    "\n",
    "\n",
    "# << Last Stage >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "Kl = 3\n",
    "Ml = 1\n",
    "n_cnt = 1\n",
    "kf = KFold(n_splits = Kl)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# 変数初期化\n",
    "y_brend_fin = np.zeros(ss_X.shape[0] * Ml).reshape(ss_X.shape[0], Ml).reshape(-1, Ml)\n",
    "model_ins_l = np.empty(Kl * Ml).reshape(Kl, Ml)\n",
    "model_ins_l = model_ins_l.astype(np.object)\n",
    "\n",
    "\n",
    "# インスタンス作成\n",
    "for ins in range(Kl):\n",
    "    model_ins_l[ins,0] = Lasso(alpha=0.1)\n",
    "    #model_ins_l[ins,0] = GaussianNB()\n",
    "    \n",
    "for i, (train_index, test_index) in enumerate(kf.split(y_brend)):\n",
    "\n",
    "    X_train, X_test = y_brend[train_index], y_brend[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "    # 学習\n",
    "    model_ins_l[i,0].fit(X_train, y_train)\n",
    "\n",
    "    # 推定\n",
    "    y_brend_fin[test_index, 0] = model_ins_l[i,0].predict(X_test).flatten()\n",
    "    \n",
    "    \n",
    "print(\"y_brend_fin.shape = \", y_brend_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 《推定時》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_model_0 = \n",
      " [[173333.33333333 171666.66666667]\n",
      " [236166.66666667 211166.66666667]\n",
      " [142666.66666667 145000.        ]\n",
      " ...\n",
      " [222333.33333333 226300.        ]\n",
      " [265000.         204000.        ]\n",
      " [257666.66666667 264166.66666667]]\n",
      "predict_model_n = \n",
      " [[189500.         205366.66666667]\n",
      " [233833.33333333 232833.33333333]\n",
      " [152000.         120666.66666667]\n",
      " ...\n",
      " [188500.         273166.66666667]\n",
      " [214333.33333333 254333.33333333]\n",
      " [278333.33333333 257626.        ]]\n",
      "y_predict_fin.shape (583,)\n",
      "y_predict_fin = \n",
      " [213012.95846678 250800.92383616 163177.93054025 272897.02615678\n",
      " 275136.79515987 163155.52300313 147916.93320262 285073.9768373\n",
      " 272105.70463502 278861.27812632 145137.48173903 262732.16407632\n",
      " 145827.21020453 304844.21236439 278861.27812632 234346.38427826\n",
      " 209321.6032782  306390.30768016 332817.62708949 176100.7921859\n",
      " 217807.53569107 192767.73737062 272897.02615678 290788.33917638\n",
      " 152753.30584235 327990.18416993 167691.46525483 199893.42922787\n",
      " 365642.80948309 282095.51407555 332817.62708949 253690.25788244\n",
      " 290788.33917638 256401.14086395 232037.17273372 271506.1786654\n",
      " 277520.947452   249690.19087709 198506.70982681 197891.28840181\n",
      " 296936.71930902 231352.87200843 284048.0501678  296936.71930902\n",
      " 200493.50340359 302072.03483794 201153.34710583 192719.2789907\n",
      " 182783.92952725 255473.52626354 192025.66932845 213012.95846678\n",
      " 223952.12213843 286128.3929608  320810.39676725 250499.62436586\n",
      " 323051.1504784  274048.9337517  202598.45244226 286128.3929608\n",
      " 286094.24828718 201124.14267107 218597.6497012  182783.92952725\n",
      " 213988.99749885 268180.57586138 237540.06813401 338749.37779429\n",
      " 219267.35205602 365642.80948309 164464.31569615 296936.71930902\n",
      " 284731.55438431 170654.88001804 292720.37478385 208403.17338921\n",
      " 270067.59597295 183629.55818195 176100.7921859  303596.41426157\n",
      " 155893.45664074 199597.5590073  286128.3929608  231942.20738498\n",
      " 148904.13878545 242740.175358   274048.9337517  176014.781705\n",
      " 143897.75694835 166226.04562243 209608.44168169 174851.87614585\n",
      " 272105.70463502 273265.84904777 271506.1786654  242435.61431468\n",
      " 217807.53569107 275136.79515987 171367.0396588  217583.46031995\n",
      " 218931.75225084 247608.291129   144116.83157554 306390.30768016\n",
      " 193190.81297559 335821.61668061 169540.7421475  274048.9337517\n",
      " 209212.65465746 246714.70301146 193875.66039745 236960.7191065\n",
      " 173150.66512808 287923.46064364 165050.6620932  178135.02065757\n",
      " 285101.36198336 198052.01079086 180333.45941487 176651.50268743\n",
      " 284731.55438431 237540.06813401 299304.07306504 278448.8618052\n",
      " 285073.9768373  150779.70441198 144285.42398772 285073.9768373\n",
      " 231821.73788999 216830.10411554 273265.84904777 306390.30768016\n",
      " 305081.93142229 286128.3929608  314011.91812138 219957.81883919\n",
      " 277520.947452   247608.291129   231689.68817713 286128.3929608\n",
      " 294031.46471101 152404.45328639 335006.45252916 293980.29266181\n",
      " 154972.74742223 164639.30149613 286579.00841695 216133.67813372\n",
      " 145792.75370633 273190.89170426 285073.9768373  292203.57503899\n",
      " 189063.15985952 178863.27692959 218931.75225084 214891.76891869\n",
      " 149757.45891921 314929.75806068 224736.38593734 183688.24387011\n",
      " 220375.13174441 198374.88392163 306390.30768016 269721.06393673\n",
      " 286128.3929608  146550.6332124  218566.18042194 175626.11481875\n",
      " 247498.96681037 176609.09318097 278716.26007473 156453.64506852\n",
      " 166385.77973208 197125.46745497 198869.96913214 237540.06813401\n",
      " 174416.10781473 340215.72837072 174753.64922408 195940.39224976\n",
      " 278448.8618052  164839.32622137 212535.24610121 158285.77669721\n",
      " 202661.0339126  232269.88863222 174079.99475805 196737.80041559\n",
      " 182444.7208678  177220.12141512 269710.17078501 251203.90291917\n",
      " 365642.80948309 258524.54583057 276955.87551602 274604.1100689\n",
      " 323051.1504784  285073.9768373  179067.01688134 154972.74742223\n",
      " 196380.37522765 236288.8424366  165594.91985997 179951.07828679\n",
      " 320810.39676725 182103.65484668 243943.64563578 168476.25311851\n",
      " 189278.7807894  282095.51407555 284048.0501678  306390.30768016\n",
      " 236942.7324729  161186.3741106  175728.29385172 199094.04450325\n",
      " 294852.54350039 212373.87969607 335006.45252916 196380.37522765\n",
      " 197891.28840181 310740.80929291 282095.51407555 242872.48911595\n",
      " 193942.45349663 296215.67772758 311967.59421284 306390.30768016\n",
      " 146550.6332124  159371.24440745 197503.62136244 217807.53569107\n",
      " 164293.54454295 323051.1504784  310740.80929291 198894.37686618\n",
      " 168498.66065562 186355.94331868 285938.89479454 268249.51400547\n",
      " 285073.9768373  182103.65484668 335006.45252916 282406.98050077\n",
      " 197891.28840181 199248.12303961 192184.67668792 323051.1504784\n",
      " 144930.19454373 219957.81883919 237390.88321513 211716.55975236\n",
      " 285029.56713391 329110.5610255  271551.58922202 248280.51724235\n",
      " 199240.13381936 175335.14978314 231142.56248895 204200.39092349\n",
      " 174724.59386131 293961.82742898 313112.56881362 269721.06393673\n",
      " 286128.3929608  163421.29370437 217583.46031995 150242.93543885\n",
      " 247608.291129   271021.04666008 178097.63452683 174724.59386131\n",
      " 274048.9337517  145137.48173903 274048.9337517  236942.7324729\n",
      " 223952.12213843 164602.51135097 273190.89170426 166050.38085175\n",
      " 174851.87614585 263381.35100837 165898.86228591 313112.56881362\n",
      " 285073.9768373  248209.17504003 404916.96957477 323051.1504784\n",
      " 173150.66512808 164130.66705104 275136.79515987 265828.38045025\n",
      " 162678.89221218 273190.89170426 203164.54841665 202940.47304554\n",
      " 217185.09421341 182032.45497645 271021.04666008 156335.41617741\n",
      " 331546.9664896  241944.4696479  212535.24610121 268180.57586138\n",
      " 164602.51135097 176100.7921859  273190.89170426 197643.72165523\n",
      " 192885.18066776 304874.64422698 276913.68121749 273265.84904777\n",
      " 231942.20738498 268741.2737183  202661.0339126  300746.00061798\n",
      " 213994.10360867 243731.12030867 335006.45252916 153431.72316125\n",
      " 284048.0501678  152404.45328639 231352.87200843 199016.05844824\n",
      " 298057.0961646  198052.01079086 240237.70867374 340215.72837072\n",
      " 183313.64978004 201153.34710583 350159.00026356 195833.99756366\n",
      " 176100.7921859  192025.66932845 203889.83959947 153036.19766623\n",
      " 261227.33397491 265828.38045025 203027.87667348 186333.53578157\n",
      " 218566.18042194 239005.29413261 175906.95866621 216513.93936458\n",
      " 159371.24440745 205423.87574447 214891.76891869 173796.86403676\n",
      " 232269.88863222 217137.30223035 189667.04381436 196380.37522765\n",
      " 313112.56881362 220375.13174441 145137.48173903 318710.49861614\n",
      " 285073.9768373  200593.79942516 297429.07827641 296936.71930902\n",
      " 180333.45941487 144585.86594323 217807.53569107 170715.03027088\n",
      " 335006.45252916 161186.3741106  213059.08319975 294031.46471101\n",
      " 268595.62804682 202661.0339126  194684.3319304  280371.01436772\n",
      " 212788.88309567 217583.46031995 214891.76891869 256985.71288445\n",
      " 278716.26007473 284731.55438431 306390.30768016 309055.51857584\n",
      " 176609.09318097 293961.82742898 266200.18824624 160992.54059091\n",
      " 186333.53578157 224736.38593734 194684.3319304  172426.50380253\n",
      " 155887.26543518 285073.9768373  196671.83968352 286994.29919743\n",
      " 285073.9768373  198149.64172704 197010.33416663 294852.54350039\n",
      " 178982.0259125  272105.70463502 192212.95455441 309055.51857584\n",
      " 144736.36102404 232889.89436601 144585.86594323 247608.291129\n",
      " 282095.51407555 192212.95455441 186333.53578157 308311.14052487\n",
      " 146550.6332124  237540.06813401 146835.50159507 318710.49861614\n",
      " 196274.64693841 199248.12303961 269486.09541389 306390.30768016\n",
      " 340215.72837072 282095.51407555 205547.7124294  230959.17872739\n",
      " 272105.70463502 213012.95846678 210530.51472576 268420.01105562\n",
      " 148201.67082068 212373.87969607 225680.84906687 174416.10781473\n",
      " 195833.99756366 169665.8764205  182501.01356204 256075.76811597\n",
      " 241570.31412158 289667.96232081 218931.75225084 145137.48173903\n",
      " 231352.87200843 197789.09679499 180440.0678507  335821.61668061\n",
      " 194460.25655929 287442.44993966 243731.12030867 247608.291129\n",
      " 284295.78605319 152753.30584235 146723.51168899 247608.291129\n",
      " 265976.25520721 273558.19365022 217583.46031995 298152.38309352\n",
      " 216971.01982697 159182.43526984 142916.25471829 365642.80948309\n",
      " 173326.30575742 192184.67668792 146723.51168899 174753.64922408\n",
      " 197713.82561644 251203.90291917 189570.12705451 193875.66039745\n",
      " 213604.72254607 168476.25311851 150779.70441198 194775.41457286\n",
      " 205363.39204161 359599.08033929 231821.73788999 240237.70867374\n",
      " 324597.204855   282406.98050077 167516.77719606 286128.3929608\n",
      " 404916.96957477 148119.87498655 212373.87969607 286289.12792369\n",
      " 286094.24828718 285126.84098192 175764.72690871 240237.70867374\n",
      " 143128.66185464 237648.10492252 294031.46471101 313112.56881362\n",
      " 247608.291129   144736.36102404 152404.45328639 216830.10411554\n",
      " 290788.33917638 275374.68129478 246714.70301146 272550.64158371\n",
      " 230959.17872739 257196.14497155 168190.05093577 273190.89170426\n",
      " 209640.90879624 152404.45328639 269721.06393673 170174.96351273\n",
      " 151180.61137725 275308.7205627  183629.55818195 146947.58706011\n",
      " 199893.42922787 215243.66341378 153036.19766623 213236.22983613\n",
      " 261132.68045074 184116.53497509 213733.64296005 231942.20738498\n",
      " 264950.29549428 282095.51407555 210448.78341875 285073.9768373\n",
      " 144866.92454678 237390.88321513 275136.79515987 258524.54583057\n",
      " 242432.87328419 235710.31793177 249690.19087709 153036.19766623\n",
      " 290788.33917638 210379.60889314 271506.1786654  176014.781705\n",
      " 183486.57603611 182032.45497645 199633.63497611 306390.30768016\n",
      " 188271.87097842 314929.75806068 198869.96913214 272897.02615678\n",
      " 251829.97915187 182854.22410321 153919.04547507 314778.18024828\n",
      " 238083.48950826 294031.46471101 290788.33917638 211240.03533364\n",
      " 277342.79176429 196568.37462996 286128.3929608  159371.24440745\n",
      " 146723.51168899 220198.01447972 220375.13174441 314011.91812138\n",
      " 177220.12141512 153334.8064014  251223.21334398 258446.84745881\n",
      " 291066.1484784  236419.69127844 304844.21236439 248498.37626023\n",
      " 209480.87820277 182444.7208678  151837.6687854  322259.53438401\n",
      " 153036.19766623 144509.49935884 216059.19254914 197503.62136244\n",
      " 167516.77719606 193349.23792968 286994.29919743 217462.00958782\n",
      " 219261.89916814 279595.9508207  298152.38309352 314778.18024828\n",
      " 232053.60130547 243943.64563578 287923.46064364]\n"
     ]
    }
   ],
   "source": [
    "# << stage 0 >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "predict_model_0 = np.zeros(ss_X.shape[0] * M0).reshape(ss_X.shape[0], -1)\n",
    "for m in range(M0):\n",
    "    predict_instance_0 = np.zeros(ss_X.shape[0] * K0).reshape(ss_X.shape[0], -1)\n",
    "    \n",
    "    for k in range(K0):\n",
    "        # 推定\n",
    "        predict_instance_0[:,k] = model_ins_0[k,m].predict(ss_X)\n",
    "        \n",
    "    predict_model_0[:,m] = np.mean(predict_instance_0, axis = 1).flatten()\n",
    "\n",
    "print(\"predict_model_0 = \\n\", predict_model_0)\n",
    "\n",
    "# << stage n >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "# n回ループ\n",
    "for n in range(n_cnt):\n",
    "    predict_model_n = np.zeros(ss_X.shape[0] * Mn).reshape(ss_X.shape[0], -1)\n",
    "    predict_model_n = predict_model_0\n",
    "    for m in range(M0):\n",
    "        predict_instance_n = np.zeros(ss_X.shape[0] * Kn).reshape(ss_X.shape[0] , -1)\n",
    "\n",
    "        for k in range(K0):\n",
    "            predict_instance_n[:,k] = model_ins_n[k,m].predict(predict_model_n)\n",
    "            \n",
    "        predict_model_n[:,m] = np.mean(predict_instance_n, axis = 1).flatten()\n",
    "        \n",
    "print(\"predict_model_n = \\n\", predict_model_n)\n",
    "\n",
    "# << Last Stage >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "# 推定\n",
    "y_predict_fin = model_ins_l[i,0].predict(predict_model_n).flatten()\n",
    "y_predict_fin.reshape(ss_X.shape[0], -1)\n",
    "\n",
    "print(\"y_predict_fin.shape\", y_predict_fin.shape)\n",
    "print(\"y_predict_fin = \\n\", y_predict_fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3232191779.8704348"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価\n",
    "MSE = mean_squared_error(y, y_predict_fin)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上をクラス化する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "class ScratchStacking():\n",
    "\n",
    "    def __init__(self, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.K0 = 3\n",
    "        self.M0 = 2\n",
    "        self.Kn = 3\n",
    "        self.Mn = 2\n",
    "        self.n_cnt = 10\n",
    "        self.Kl = 3\n",
    "        self.Ml = 1\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X_train_list = []\n",
    "        X_test_list = []\n",
    "        y_train_list = []\n",
    "        y_test_list = []\n",
    "        model_ins = []\n",
    "\n",
    "        model_ins1 = []\n",
    "        model_ins2 = []\n",
    "\n",
    "        # << stage 0 >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        # クロスバリデーション\n",
    "        kf = KFold(n_splits = self.K0)\n",
    "        kf.get_n_splits(ss_X)\n",
    "\n",
    "        # 変数初期化\n",
    "        y_brend = np.zeros(X.shape[0] * self.M0).reshape(X.shape[0], self.M0).reshape(-1, self.M0)\n",
    "        model_ins_0 = np.empty(self.K0 * self.M0).reshape(self.K0, self.M0)\n",
    "        model_ins_0 = model_ins_0.astype(np.object)\n",
    "\n",
    "        # インスタンス作成\n",
    "        for ins in range(self.K0):\n",
    "            model_ins_0[ins,0] = GaussianNB()\n",
    "            model_ins_0[ins,1] = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "\n",
    "        # データ分割\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            for j in range(self.M0):\n",
    "                # 学習\n",
    "                model_ins_0[i,j].fit(X_train, y_train)\n",
    "\n",
    "                # 推定\n",
    "                y_brend[test_index, j] = model_ins_0[i,j].predict(X_test).flatten()\n",
    "\n",
    "        # << stage n >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        self.n_cnt = 1\n",
    "        kf = KFold(n_splits = self.Kn)\n",
    "        kf.get_n_splits(X)\n",
    "\n",
    "        # 変数初期化\n",
    "        model_ins_n = np.empty(self.Kn * self.Mn).reshape(self.Kn, self.Mn)\n",
    "        model_ins_n = model_ins_n.astype(np.object)\n",
    "\n",
    "        # インスタンス作成\n",
    "        for ins in range(self.K0):\n",
    "            model_ins_n[ins,0] = GaussianNB()\n",
    "            model_ins_n[ins,1] = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "        # n回ループ\n",
    "        for n in range(self.n_cnt):\n",
    "            for i, (train_index, test_index) in enumerate(kf.split(y_brend)):\n",
    "                X_train, X_test = y_brend[train_index], y_brend[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "                for j in range(self.Mn):\n",
    "                    # 学習\n",
    "                    model_ins_n[i,j].fit(X_train, y_train)\n",
    "\n",
    "                    # 推定\n",
    "                    y_brend[test_index, j] = model_ins_n[i,j].predict(X_test).flatten()\n",
    "\n",
    "        # << Last Stage >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        kf = KFold(n_splits = self.Kl)\n",
    "        kf.get_n_splits(X)\n",
    "\n",
    "        # 変数初期化\n",
    "        y_brend_fin = np.zeros(X.shape[0] * self.Ml).reshape(X.shape[0], self.Ml).reshape(-1, self.Ml)\n",
    "        model_ins_l = np.empty(self.Kl * self.Ml).reshape(self.Kl, self.Ml)\n",
    "        model_ins_l = model_ins_l.astype(np.object)\n",
    "\n",
    "        # インスタンス作成\n",
    "        for ins in range(self.Kl):\n",
    "            model_ins_l[ins,0] = Lasso(alpha=0.1)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(y_brend)):\n",
    "\n",
    "            X_train, X_test = y_brend[train_index], y_brend[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # 学習\n",
    "            model_ins_l[i,0].fit(X_train, y_train)\n",
    "\n",
    "            # 推定\n",
    "            y_brend_fin[test_index, 0] = model_ins_l[i,0].predict(X_test).flatten()\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"y_brend_fin.shape = \", y_brend_fin.shape)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        # << stage 0 >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        predict_model_0 = np.zeros(X.shape[0] * self.M0).reshape(X.shape[0], -1)\n",
    "        for m in range(self.M0):\n",
    "            predict_instance_0 = np.zeros(X.shape[0] * self.K0).reshape(X.shape[0], -1)\n",
    "\n",
    "            for k in range(self.K0):\n",
    "                # 推定\n",
    "                predict_instance_0[:,k] = model_ins_0[k,m].predict(X)\n",
    "\n",
    "            predict_model_0[:,m] = np.mean(predict_instance_0, axis = 1).flatten()\n",
    "\n",
    "        # << stage n >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        # n回ループ\n",
    "        for n in range(self.n_cnt):\n",
    "            predict_model_n = np.zeros(X.shape[0] * self.Mn).reshape(X.shape[0], -1)\n",
    "            predict_model_n = predict_model_0\n",
    "            for m in range(self.M0):\n",
    "                predict_instance_n = np.zeros(X.shape[0] * self.Kn).reshape(X.shape[0] , -1)\n",
    "\n",
    "                for k in range(self.K0):\n",
    "                    predict_instance_n[:,k] = model_ins_n[k,m].predict(predict_model_n)\n",
    "\n",
    "                predict_model_n[:,m] = np.mean(predict_instance_n, axis = 1).flatten()\n",
    "\n",
    "\n",
    "        # << Last Stage >> ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■\n",
    "        # 推定\n",
    "        y_predict_fin = model_ins_l[i,0].predict(predict_model_n).flatten()\n",
    "        y_predict_fin.reshape(X.shape[0], -1)\n",
    "        \n",
    "        return y_predict_fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScratchStack = ScratchStacking()\n",
    "ScratchStack.fit(ss_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ScratchStack.predict(ss_X)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3232191779.8704348"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価\n",
    "MSE = mean_squared_error(y, y_pred)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果は上記のようになり、これまでのブレンディング/バギングと比べてスタッキングで最高の精度3232191779.8704348が出た。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
