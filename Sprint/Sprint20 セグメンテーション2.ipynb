{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wZfGwxHq5Qv"
   },
   "source": [
    "# Sprint20 セグメンテーション2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcATiVc_sEaq"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 106844,
     "status": "ok",
     "timestamp": 1593344512863,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "HBQ56XpOsNax",
    "outputId": "2bb6eb4d-e5b8-4adf-edea-4518eb0c0058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
      "\u001b[K     |████████████████████████████████| 412.3MB 33kB/s \n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 18.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.30.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 33.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (47.3.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
      "Building wheels for collected packages: gast\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=b8f7fe47631342dd89de5c1bf56e3784bf71e04f81e1b87ec8817c57e9e00acf\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built gast\n",
      "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow\n",
      "  Found existing installation: tensorboard 2.2.2\n",
      "    Uninstalling tensorboard-2.2.2:\n",
      "      Successfully uninstalled tensorboard-2.2.2\n",
      "  Found existing installation: tensorflow-estimator 2.2.0\n",
      "    Uninstalling tensorflow-estimator-2.2.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
      "  Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "  Found existing installation: tensorflow 2.2.0\n",
      "    Uninstalling tensorflow-2.2.0:\n",
      "      Successfully uninstalled tensorflow-2.2.0\n",
      "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "gast",
         "tensorboard",
         "tensorflow"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1981,
     "status": "ok",
     "timestamp": 1593344538733,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "WrMSz30ZsQhb",
    "outputId": "67e23b2b-29b5-4a4b-c62b-46ebcf0c2876"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36204,
     "status": "ok",
     "timestamp": 1593344577219,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "e1ikX8qFs0fH",
    "outputId": "7a767880-2b9c-4eb5-8f83-c5f0e9e4546b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "# 自分のマイドライブにマウントする\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:39.259864Z",
     "start_time": "2020-03-25T14:39:39.039884Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1702,
     "status": "ok",
     "timestamp": 1593344590943,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "0LGgcq-3sEar",
    "outputId": "29071a43-789a-4c80-a82c-794eaafb5400"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:43.879310Z",
     "start_time": "2020-03-25T14:39:43.876304Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1593344595085,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "iJB__Js0sEau"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:44.446808Z",
     "start_time": "2020-03-25T14:39:44.431975Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 494,
     "status": "ok",
     "timestamp": 1593344601157,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "V79OONw1sEaw"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqlZ-5o7sEay"
   },
   "source": [
    "### Data loading & depth merge:  \n",
    "データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:47.676622Z",
     "start_time": "2020-03-25T14:39:47.485724Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2246,
     "status": "ok",
     "timestamp": 1593344607837,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "5b6B9c6NsEaz",
    "outputId": "2dc14646-6ff2-4b20-cead-18b8f08c1897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...\n",
      "1  3cb59a4fdc                                             1 5656\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...\n",
      "3  c78c89577c                                              101 1\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  3e06571ef3      1 1\n",
      "1  a51b08d882      1 1\n",
      "2  c32590b06f      1 1\n",
      "3  15f7a047c7      1 1\n",
      "4  e8827bc832      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  2c45b152f1  99 3 197 6 295 9 395 10 494 12 594 13 694 14 7...  312\n",
      "1  3cb59a4fdc                                             1 5656  603\n",
      "2  e185ab5dc1  4647 2 4748 10 4849 18 4950 25 5051 29 5152 34...  687\n",
      "3  c78c89577c                                              101 1  236\n",
      "4  6306dd3a8e  1 30 102 29 203 29 304 28 405 27 506 27 607 26...  805\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/sample_submission.csv')\n",
    "depth = pd.read_csv('/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/depths.csv')\n",
    "\n",
    "train_src = '/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1048,
     "status": "ok",
     "timestamp": 1593153230922,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "O5UtMappUs3M",
    "outputId": "afa1b628-1fd9-4ff1-f8f1-b79c02019c1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2369,
     "status": "ok",
     "timestamp": 1593153244556,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "UGJAFNnjUxZv",
    "outputId": "4682fa10-4024-4658-fab7-81a756e9599c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8ojG5m_sEa2"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1593344650165,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "SLUXam5PvZT-",
    "outputId": "6b7c1f58-36f6-440b-f9b9-a84e9fc132f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train\n"
     ]
    }
   ],
   "source": [
    "cd \"/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TZ4QWrk0cI5"
   },
   "source": [
    "イメージ(訓練)/マスク（正解）読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:58.581787Z",
     "start_time": "2020-03-25T14:39:50.781893Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524937,
     "status": "ok",
     "timestamp": 1593346407143,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "ys09KGXIsEa2",
    "outputId": "08c6d3d7-77bc-4dad-f3c4-7e099b375256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/My Drive/DIC/Segmantation/TGS_Salt_Identification_Challenge/competition_data/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3225,
     "status": "ok",
     "timestamp": 1593346452580,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "YAWFFodoxvn_"
   },
   "outputs": [],
   "source": [
    "# 画像のロードにかなりの時間がかかるので、読込済みのデータを保存しておく。\n",
    "import pickle\n",
    "with open('/content/drive/My Drive/DIC/Segmantation/X_train.pkl', 'wb') as xtrain:\n",
    "    pickle.dump(X_train, xtrain)\n",
    "\n",
    "with open('/content/drive/My Drive/DIC/Segmantation/y_train.pkl', 'wb') as ytrain:\n",
    "    pickle.dump(y_train, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY_pTnKXzGUj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:39:59.083122Z",
     "start_time": "2020-03-25T14:39:58.584544Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1022,
     "status": "ok",
     "timestamp": 1593346470154,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "okRcYDUSsEa4",
    "outputId": "71910668-e559-42e7-b2c2-2b75d22ae20d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f20a17f5f60>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ランダム抽出\n",
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "# グレースケールで表示\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OAoFsfV_sEa6"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):  \n",
    "塩分含有率の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:08.034054Z",
     "start_time": "2020-03-25T14:40:07.987000Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 486,
     "status": "ok",
     "timestamp": 1593346474877,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "iTFc2qSKsEa7"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZ5xdSrcsEa9"
   },
   "source": [
    "### Prepare data for training:\n",
    "前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.924796Z",
     "start_time": "2020-03-25T14:40:09.595933Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22459,
     "status": "ok",
     "timestamp": 1593346504773,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "-O1sG1x4sEa9",
    "outputId": "fb7f259d-eac5-4c23-f33d-45b1d488a9fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "# デフォルトのイメージサイズを224ｘ224にリサイズ\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "# K-hold法を用いる\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWK7PUzmsEa_"
   },
   "source": [
    "### Loss functions & metric:  \n",
    "損失関数と評価関数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:35.952868Z",
     "start_time": "2020-03-25T14:40:35.927679Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 702,
     "status": "ok",
     "timestamp": 1593346511408,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "YTAIjQEAsEbA"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qnG3POgksEbC"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7-aAldw5RiOR"
   },
   "source": [
    "(和訳)  \n",
    "ResNet50 では，各ブロックの最後にプーリング層があるので，プーリングの直前に中間層から特徴を抽出することができます．\n",
    "\n",
    "このようにして、最初の層を追加抽出器として追加した場合には、5層から特徴を抽出することになります。デフォルトの入力サイズは(224, 224, 3)とします。レイヤーは以下のようになります。\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "注意点としては、ノートブック内の同じTFセッションでモデルが作成されるたびにレイヤー名が変わるので、上記のレイヤー名は最初に作成されたモデルに対応しています。セッションをリセットするには、K.clear_session()を呼び出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:43.034360Z",
     "start_time": "2020-03-25T14:40:35.954603Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10171,
     "status": "ok",
     "timestamp": 1593350208985,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "V9GUDLqrsEbC",
    "outputId": "79c4628f-0525-4315-e18b-d13150a937bc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 1s 0us/step\n",
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 512)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 512)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 512)  0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 28, 512)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 1024) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 1024) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 1024) 0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 1024) 0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 1024) 0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 1024) 0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 2048)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 2048)   0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 2048)   0           add_22[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 入力サイズ：224x224 3ch\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "# レイヤ―詳細を表示\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOYlcaKrsEbF"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXzH31rTSJxx"
   },
   "source": [
    "(和訳)\n",
    "ResNet50 の特徴量がセグメンテーションモデルのエンコーダ部分の基礎となりますが、今度はデコーダ部分が必要です。この部分では、独自のブロックを作成する必要があります。ここでは、非常に基本的なブロックと、より複雑な構造を持つ第二のブロックを作成してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:40:46.197121Z",
     "start_time": "2020-03-25T14:40:46.188335Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1593350216768,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "hchdsqnbsEbF"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, \n",
    "        block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    # 1block : Conv ⇒　BatchNormal　⇒　PReLU\n",
    "    x_dec = Conv2D(num_filters, \n",
    "                    conv_dim,\n",
    "                    padding='same',\n",
    "                    name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(layer_name, \n",
    "                                block_name,\n",
    "                                num_filters=32,\n",
    "                                conv_dim=(3, 3),\n",
    "                                dropout_frac=0.2):\n",
    "\n",
    "    # 1block : (Conv ⇒　BatchNormal　⇒　PReLU　⇒　Dropout)　⇒　\n",
    "    # 2block : (Conv ⇒　BatchNormal　⇒　PReLU　⇒　Dropout ⇒　Conv ⇒　BatchNormal　⇒　PReLU　⇒　Dropout )\n",
    "    x_dec = Conv2D(num_filters, \n",
    "                    conv_dim,\n",
    "                    padding='same',\n",
    "                    name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(num_filters // 2, \n",
    "                    conv_dim,\n",
    "                    padding='same',\n",
    "                    name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(num_filters, \n",
    "                    conv_dim,\n",
    "                    padding='same',\n",
    "                    name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTM3veCasEbH"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model.  \n",
    "エンコーダーブロックにResnetを用いたモデルを作成。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:54:51.684488Z",
     "start_time": "2020-03-25T14:54:51.673231Z"
    },
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1593350223171,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "JR6eK8HvsEbH"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # ResNetをベースモデルとする。\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # encoder1～5を定義\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('conv1').output # activation_1\n",
    "    encoder2 = base_model.get_layer('res2c_branch2c').output # activation_10\n",
    "    encoder3 = base_model.get_layer('res3d_branch2c').output # activation_22\n",
    "    encoder4 = base_model.get_layer('res4f_branch2c').output # activation_40\n",
    "    encoder5 = base_model.get_layer('res5c_branch2c').output # activation_40\n",
    "\n",
    "    # センターブロック\n",
    "    center = decoder_block(encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "\n",
    "    # デコーダー部\n",
    "    # すべてのデコーダーブロックはエンコーダーブロックから連結されています。\n",
    "    # これによりスキップコネクションが作成されます。\n",
    "    # その後、デコーダー出力は、エンコーダー出力部分と同じ次元にアップサンプリングされる。\n",
    "\n",
    "    # encoder4とdecoder4をスキップ接続\n",
    "    decoder4 = decoder_block(concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    # encoder3とdecoder3をスキップ接続\n",
    "    decoder3 = decoder_block(concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    # encoder2とdecoder2をスキップ接続\n",
    "    decoder2 = decoder_block(concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    # encoder1とdecoder1をスキップ接続\n",
    "    decoder1 = decoder_block(concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    # セグメンテーションのための最終的なアップサンプリングとデコーダーブロック\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWvofvnnsEbJ"
   },
   "source": [
    "### Inspect created model:  \n",
    "作成したモデルの検査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T14:55:00.601042Z",
     "start_time": "2020-03-25T14:54:53.772115Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9070,
     "status": "ok",
     "timestamp": 1593350242821,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "rx0CJuyXsEbJ",
    "outputId": "bf36db48-1898-4815-fcf6-120086eca66b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,903,873\n",
      "Trainable params: 42,852,737\n",
      "Non-trainable params: 51,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "# imagenetの学習済み重みを利用\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_Dx52IBfyyB"
   },
   "source": [
    "### ★RasNetの各レイヤーの詳細については、[補足資料](https://github.com/takatoshi-ii/diveintocode-ml/blob/master/Sprint/Splint20/Sprint20_Detail.pdf)「ResNet-EncoderDecoder」を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nvISa1r1sEbL"
   },
   "source": [
    "### Train model(resnet):\n",
    "EncoderをResnetで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-25T17:37:03.773696Z",
     "start_time": "2020-03-25T14:58:43.483800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2467511,
     "status": "ok",
     "timestamp": 1593352722789,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "GzW7zm40sEbL",
    "outputId": "587877f1-8e02-40e5-a4c2-b7335f936c23",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,970,161\n",
      "Trainable params: 48,915,857\n",
      "Non-trainable params: 54,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 253s 79ms/step - loss: 0.7954 - my_iou_metric: 0.3266 - val_loss: 20.6216 - val_my_iou_metric: 0.1321\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.13213, saving model to unet_resnet.h5\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.6276 - my_iou_metric: 0.4535 - val_loss: 1.9923 - val_my_iou_metric: 0.0225\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.13213\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 233s 73ms/step - loss: 0.5389 - my_iou_metric: 0.4887 - val_loss: 2.8416 - val_my_iou_metric: 0.1256\n",
      "\n",
      "Epoch 00003: val_my_iou_metric did not improve from 0.13213\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.5004 - my_iou_metric: 0.5253 - val_loss: 3.0361 - val_my_iou_metric: 0.1636\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.13213 to 0.16363, saving model to unet_resnet.h5\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.4638 - my_iou_metric: 0.5422 - val_loss: 0.8367 - val_my_iou_metric: 0.4174\n",
      "\n",
      "Epoch 00005: val_my_iou_metric improved from 0.16363 to 0.41738, saving model to unet_resnet.h5\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 233s 73ms/step - loss: 0.4399 - my_iou_metric: 0.5715 - val_loss: 0.6514 - val_my_iou_metric: 0.5805\n",
      "\n",
      "Epoch 00006: val_my_iou_metric improved from 0.41738 to 0.58050, saving model to unet_resnet.h5\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.4165 - my_iou_metric: 0.5948 - val_loss: 0.4284 - val_my_iou_metric: 0.6023\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.58050 to 0.60225, saving model to unet_resnet.h5\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.3982 - my_iou_metric: 0.6043 - val_loss: 0.4626 - val_my_iou_metric: 0.6286\n",
      "\n",
      "Epoch 00008: val_my_iou_metric improved from 0.60225 to 0.62862, saving model to unet_resnet.h5\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.3872 - my_iou_metric: 0.6015 - val_loss: 0.5530 - val_my_iou_metric: 0.5576\n",
      "\n",
      "Epoch 00009: val_my_iou_metric did not improve from 0.62862\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 232s 73ms/step - loss: 0.3658 - my_iou_metric: 0.6269 - val_loss: 1.4052 - val_my_iou_metric: 0.5283\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.62862\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "\n",
    "# unet_resnetを用いてモデルを作成\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "# チェックポイントの設定\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 10  # 25\n",
    "batch_size = 16\n",
    "\n",
    "# 学習実行\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 28445,
     "status": "ok",
     "timestamp": 1593352752223,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "RbGw451RHHfT"
   },
   "outputs": [],
   "source": [
    "# Colabに切断された時の為に、学習済みモデルを保存する。\n",
    "mport pickle\n",
    "with open('/content/drive/My Drive/DIC/Segmantation/resnet_model_depth.pkl', 'wb') as resnet_model:\n",
    "    pickle.dump(model_depth, resnet_model)\n",
    "with open('/content/drive/My Drive/DIC/Segmantation/resnet_history.pkl', 'wb') as resnet_history:\n",
    "    pickle.dump(history, resnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1593352773953,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "mkdQvZHrOXMr",
    "outputId": "20b8f1af-e4fa-420c-a3dd-20778c814fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': [20.621565532684325, 1.9923272705078126, 2.8416359090805052, 3.036086359024048, 0.8367270231246948, 0.6513992747664452, 0.4283580502867699, 0.46263055741786957, 0.5529740026593208, 1.4051842737197875], 'val_my_iou_metric': [0.13212500512599945, 0.02250000089406967, 0.12562498450279236, 0.16362501680850983, 0.41737502813339233, 0.5805000066757202, 0.6022500395774841, 0.6286249756813049, 0.5576249957084656, 0.5282501578330994], 'loss': [0.7954429438710213, 0.6276052249968052, 0.5389478355646133, 0.5003972458839416, 0.46384316124022007, 0.4399152096733451, 0.4165278809517622, 0.3981844084709883, 0.38723831925541163, 0.36576554339379075], 'my_iou_metric': [0.32662496, 0.45350003, 0.4886563, 0.5252501, 0.54215616, 0.5715, 0.5947813, 0.6042811, 0.6014999, 0.6269375], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "85bX_C3pWaKk"
   },
   "source": [
    "### Loss/Epoch およびIoU/Epochのグラフを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1471,
     "status": "ok",
     "timestamp": 1593353350654,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "nOBBy8FONjFQ",
    "outputId": "e567d73d-227b-4915-b0b4-73fefb40525f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_iou_metric = history.history['my_iou_metric']\n",
    "val_my_iou_metric = history.history['val_my_iou_metric']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "res_net_lr = history.history['lr']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8), facecolor='white')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, my_iou_metric, label='Training my_iou_metric')\n",
    "plt.plot(epochs_range, val_my_iou_metric, label='val_my_iou_metric Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"iou_metric\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LT0843VbaTq"
   },
   "source": [
    "val_Lossは１Epochあたりで急激に減少し、0.4前後に収束している。  \n",
    "val_IoUに関して、rasnetは層数が多い為、立ち上がりが遅いが、3Epoch辺りで急上昇し、0.6前後で収束している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fl4rdoqYsEbN"
   },
   "source": [
    "### Validation set prediction and resizing to original size:  \n",
    "検証セットの予測とオリジナルサイズへのリサイズ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18777,
     "status": "ok",
     "timestamp": 1593353140876,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "m_sygQ7jsEbO"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdDbpI0tuLmm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qN6KjV_tsEbP"
   },
   "source": [
    "### Threshold optimization:   \n",
    "しきい値の最適化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 509,
     "status": "ok",
     "timestamp": 1593353147901,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "OiZx-6QVsEbQ"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57665,
     "status": "ok",
     "timestamp": 1593353212324,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "HXyGUGgosEbR",
    "outputId": "d21e9120-160d-4ad8-99d7-d18039720681"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/35 [00:01<00:55,  1.64s/it]\u001b[A\n",
      "  6%|▌         | 2/35 [00:03<00:54,  1.64s/it]\u001b[A\n",
      "  9%|▊         | 3/35 [00:04<00:52,  1.64s/it]\u001b[A\n",
      " 11%|█▏        | 4/35 [00:06<00:51,  1.65s/it]\u001b[A\n",
      " 14%|█▍        | 5/35 [00:08<00:49,  1.65s/it]\u001b[A\n",
      " 17%|█▋        | 6/35 [00:09<00:47,  1.64s/it]\u001b[A\n",
      " 20%|██        | 7/35 [00:11<00:45,  1.64s/it]\u001b[A\n",
      " 23%|██▎       | 8/35 [00:13<00:44,  1.63s/it]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:14<00:42,  1.63s/it]\u001b[A\n",
      " 29%|██▊       | 10/35 [00:16<00:40,  1.62s/it]\u001b[A\n",
      " 31%|███▏      | 11/35 [00:18<00:39,  1.63s/it]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:19<00:37,  1.63s/it]\u001b[A\n",
      " 37%|███▋      | 13/35 [00:21<00:36,  1.64s/it]\u001b[A\n",
      " 40%|████      | 14/35 [00:22<00:34,  1.63s/it]\u001b[A\n",
      " 43%|████▎     | 15/35 [00:24<00:32,  1.63s/it]\u001b[A\n",
      " 46%|████▌     | 16/35 [00:26<00:30,  1.63s/it]\u001b[A\n",
      " 49%|████▊     | 17/35 [00:27<00:29,  1.64s/it]\u001b[A\n",
      " 51%|█████▏    | 18/35 [00:29<00:28,  1.65s/it]\u001b[A\n",
      " 54%|█████▍    | 19/35 [00:31<00:26,  1.65s/it]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:32<00:24,  1.64s/it]\u001b[A\n",
      " 60%|██████    | 21/35 [00:34<00:23,  1.66s/it]\u001b[A\n",
      " 63%|██████▎   | 22/35 [00:36<00:21,  1.64s/it]\u001b[A\n",
      " 66%|██████▌   | 23/35 [00:37<00:19,  1.64s/it]\u001b[A\n",
      " 69%|██████▊   | 24/35 [00:39<00:18,  1.64s/it]\u001b[A\n",
      " 71%|███████▏  | 25/35 [00:40<00:16,  1.63s/it]\u001b[A\n",
      " 74%|███████▍  | 26/35 [00:42<00:14,  1.63s/it]\u001b[A\n",
      " 77%|███████▋  | 27/35 [00:44<00:12,  1.62s/it]\u001b[A\n",
      " 80%|████████  | 28/35 [00:45<00:11,  1.63s/it]\u001b[A\n",
      " 83%|████████▎ | 29/35 [00:47<00:09,  1.62s/it]\u001b[A\n",
      " 86%|████████▌ | 30/35 [00:49<00:08,  1.63s/it]\u001b[A\n",
      " 89%|████████▊ | 31/35 [00:50<00:06,  1.63s/it]\u001b[A\n",
      " 91%|█████████▏| 32/35 [00:52<00:04,  1.62s/it]\u001b[A\n",
      " 94%|█████████▍| 33/35 [00:53<00:03,  1.63s/it]\u001b[A\n",
      " 97%|█████████▋| 34/35 [00:55<00:01,  1.63s/it]\u001b[A\n",
      "100%|██████████| 35/35 [00:57<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "# 0.2～0.9の範囲で0.02刻みで閾値を設定。\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "\n",
    "# すべてのしきい値について、予測をバイナリ配列に設定します。\n",
    "# しきい値を超える値は1として扱われ、残りは0として扱われます。\n",
    "# しきい値をループして、上記のIoU関数に基づいてしきい値のIoUを計算します。\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true, np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1593353217051,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "Se09hdn9sEbT",
    "outputId": "ab81b62c-1eea-4719-a877-fdbaf8c8f372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5830 at threshold: 0.600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.567786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.014903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.530750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.575125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.578875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.583000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.567786\n",
       "std     0.204939   0.014903\n",
       "min     0.200000   0.530750\n",
       "25%     0.370000   0.555000\n",
       "50%     0.540000   0.575125\n",
       "75%     0.710000   0.578875\n",
       "max     0.880000   0.583000"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHwCkZVdwnER"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1593353378387,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "HBeY6V3QsEbV",
    "outputId": "7b43dbd5-be5a-4bbc-fb0a-f60b04b4812e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2047e7b518>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dg53MuZzw12a"
   },
   "source": [
    "bestなIoUは、threshold＝0.600の時のIoU＝0.5830"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ihgYGuecsEbX"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gQXyYizw_k9"
   },
   "source": [
    "結論：  \n",
    "●事前学習済みモデルは、セグメンテーションの問題に使用できます。  \n",
    "　・一部のアーキテクチャは問題に簡単に適応できます（ResNetなど）  \n",
    "\n",
    "　・他のアーキテクチャでは、特徴抽出とパディングのために適切なレイヤーを選択するための実験がさらに必要になる場合があります  \n",
    "　　（Xceptionの使用例）  \n",
    "\n",
    "　・特徴抽出のためのレイヤー選択を試すことができます  \n",
    "　・一部のモデルでは、エンコーダー/デコーダーブロックの数を試すこともできます  \n",
    "\n",
    "●しきい値の最適化は、トレーニング中の直接的なメトリックの最適化が難しい問題で重要です。  \n",
    "\n",
    "　・より複雑な最適化手法（scipy optimizeから）を使用することは可能ですが、トレインとテストセットの分布が非常に類似していない限り、最適化できない可能性があります。検証セットのしきい値やその他のパラメーターを最適化しすぎると、テストセットの結果が悪くなる可能性があります。  \n",
    "\n",
    "●さまざまな損失の実験-BCE、Dice、BCEとDice、Lovash損失の組み合わせ。  \n",
    "\n",
    "　・様々な損失で訓練されたモデルは、異なる結果をもたらす可能性があり、それはエンセンブルするときに有利かもしれません。  \n",
    "\n",
    "可能な実験：  \n",
    "　●作成したセグメンテーションモデルでデコーダーブロックのタイプを変更  \n",
    "　●独自のデコーダーブロックを作成  \n",
    "　●他の損失を伴うトレーニング  \n",
    "　●学習時間を長く  \n",
    "　●BCE /ダイスでトレーニングし、モデルを保存してから、ウェイトをロードし、Lovash 損失で微調整します　　\n",
    "　●しきい値の最適化のためにさまざまな範囲と間隔を試してください　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1593353267058,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "pAmka1_vsEbX",
    "outputId": "070d6c9c-b5b7-4393-fad6-8be337530da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1593353272005,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "EF2IWLxOsEbZ"
   },
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uhoDey_lrviv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8c3EJ_1AzT7"
   },
   "source": [
    "## 【問題1】コードレビュー\n",
    "\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "\n",
    "《視点例》\n",
    "\n",
    "\n",
    "前回使用した実装とはどのように違うのか\n",
    "転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZOD5wIXAzvM"
   },
   "source": [
    "Sprint19のモデルは、\n",
    "＜Encoder＞  \n",
    "Input→  \n",
    "Conv→Conv→MaxPool  x３回(チャンネル数：64→128→256→512)  \n",
    "Conv→Conv→DropOut→MaxPool (チャンネル数：→1024)  \n",
    "＜中間層＞  \n",
    "Conv→Conv→DropOut→UpConv (チャンネル数：→512)  \n",
    "＜Decoder＞  \n",
    "Concat→Conv→Conv→UpConvx３回(チャンネル数：→256→128→64)  \n",
    "Concat→Conv→Conv→Conv  (チャンネル数：64→2→1)  \n",
    "\n",
    "また、Encoder層からDecoder層へ4回スキップコネクションにより特徴マップを連結させている\n",
    "\n",
    "Sprint20のモデルは、  \n",
    "＜Encoder＞  \n",
    "ResNet50により50層構造となっている。\n",
    "＜Decoder＞   \n",
    "bottleneckアーキテクチャを採用し、計算負荷を増やすことなく多層化し、精度を向上させている。\n",
    "\n",
    "Encoder層からDecoder層へ4回スキップコネクションにより特徴マップを連結させている\n",
    "\n",
    "### ★Sprint20の各レイヤーについての詳細については、[補足資料](https://github.com/takatoshi-ii/diveintocode-ml/blob/master/Sprint/Splint20/Sprint20_Detail.pdf)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MHbjwTtOAzyp"
   },
   "source": [
    "### 転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NV5hw3ESAz3N"
   },
   "source": [
    "⇒①以下のコードでimagenetの学習済み重みを呼び出している。\n",
    "```python\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "```\n",
    "\n",
    "Encode部分のResnetとDecode部分の自作モデル間で以下のスキップコネクションを接続している。\n",
    "Encode　　　　　　　Decode  \n",
    "conv1　　　　 　⇒　concatenate_5  \n",
    "res2c_branch2c　⇒　concatenate_4  \n",
    "res3d_branch2c　⇒　concatenate_3  \n",
    "res4f_branch2c　⇒　concatenate_2  \n",
    "res5c_branch2c　⇒　concatenate_1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWyArr88Az9r"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-VJjrCwFrxYs"
   },
   "source": [
    "## 【問題2】コードの書き換え\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CM726ktnsRZT"
   },
   "source": [
    "### Encoder features - VGG19:\n",
    "\n",
    "\n",
    "- 'block2_conv2', shape: (None, 112, 112, 64)\n",
    "- 'block3_conv4', shape: (None, 56, 56, 256)\n",
    "- 'block4_conv4', shape: (None, 28, 28, 512)\n",
    "- 'block5_conv4', shape: (None, 14, 14, 1024)\n",
    "- 'block5_pool', shape: (None, 7, 7, 2048)\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call K.clear_session()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvWHqzrq_nSN"
   },
   "source": [
    "### ★Skip Connectionの詳細については、[補足資料](https://github.com/takatoshi-ii/diveintocode-ml/blob/master/Sprint/Splint20/Sprint20_Detail.pdf)「Encoder部の比較」を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12090,
     "status": "ok",
     "timestamp": 1593346557594,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "20Ta0m1ArnH_",
    "outputId": "92330838-6942-42d1-d8d1-4269ca5cdc95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 1s 0us/step\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "base_VGG_model = VGG19(input_shape=input_size, include_top=False)\n",
    "base_VGG_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNXG2IXa30Jg"
   },
   "source": [
    "### Model definition:\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1593347615532,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "aEoGO_7R0TH7"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_vgg19_model = VGG19(input_shape=input_size, \n",
    "                            include_top=False,\n",
    "                            weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_vgg19_model.get_layer('block2_conv2').output # activation_1\n",
    "    encoder2 = base_vgg19_model.get_layer('block3_conv4').output # activation_10\n",
    "    encoder3 = base_vgg19_model.get_layer('block4_conv4').output # activation_22\n",
    "    encoder4 = base_vgg19_model.get_layer('block5_conv4').output # activation_40\n",
    "    encoder5 = base_vgg19_model.get_layer('block5_pool').output # activation_40\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_vgg19_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2EcNh5QpYXFK"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2120,
     "status": "ok",
     "timestamp": 1593347623084,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "vxk3QebMnxZJ",
    "outputId": "b03d3be1-5fdf-463a-9d14-eafba392e6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,160,513\n",
      "Trainable params: 28,158,401\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model_vgg19 = unet_vgg19(input_size, decoder_block_simple, weights='imagenet')\n",
    "model_vgg19.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_dgKw2x1wXT"
   },
   "source": [
    "Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2417451,
     "status": "ok",
     "timestamp": 1593350045032,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "ZEHCcmCMrnL1",
    "outputId": "15786d63-8e95-4517-fbc6-c93f1ce8a631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 34,226,801\n",
      "Trainable params: 34,221,521\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/10\n",
      "3200/3200 [==============================] - 244s 76ms/step - loss: 0.9218 - my_iou_metric: 0.1342 - val_loss: 4.8911 - val_my_iou_metric: 0.1336\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.13363, saving model to unet_vgg19.h5\n",
      "Epoch 2/10\n",
      "3200/3200 [==============================] - 238s 75ms/step - loss: 0.7940 - my_iou_metric: 0.2110 - val_loss: 1.3290 - val_my_iou_metric: 0.1678\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.13363 to 0.16775, saving model to unet_vgg19.h5\n",
      "Epoch 3/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.7247 - my_iou_metric: 0.2693 - val_loss: 0.9096 - val_my_iou_metric: 0.2961\n",
      "\n",
      "Epoch 00003: val_my_iou_metric improved from 0.16775 to 0.29612, saving model to unet_vgg19.h5\n",
      "Epoch 4/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.6795 - my_iou_metric: 0.3515 - val_loss: 0.7739 - val_my_iou_metric: 0.4900\n",
      "\n",
      "Epoch 00004: val_my_iou_metric improved from 0.29612 to 0.49000, saving model to unet_vgg19.h5\n",
      "Epoch 5/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.6338 - my_iou_metric: 0.4296 - val_loss: 0.9880 - val_my_iou_metric: 0.3178\n",
      "\n",
      "Epoch 00005: val_my_iou_metric did not improve from 0.49000\n",
      "Epoch 6/10\n",
      "3200/3200 [==============================] - 238s 74ms/step - loss: 0.6038 - my_iou_metric: 0.4305 - val_loss: 0.8610 - val_my_iou_metric: 0.2645\n",
      "\n",
      "Epoch 00006: val_my_iou_metric did not improve from 0.49000\n",
      "Epoch 7/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.5936 - my_iou_metric: 0.4479 - val_loss: 0.5588 - val_my_iou_metric: 0.5423\n",
      "\n",
      "Epoch 00007: val_my_iou_metric improved from 0.49000 to 0.54225, saving model to unet_vgg19.h5\n",
      "Epoch 8/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.5655 - my_iou_metric: 0.4616 - val_loss: 0.5592 - val_my_iou_metric: 0.5139\n",
      "\n",
      "Epoch 00008: val_my_iou_metric did not improve from 0.54225\n",
      "Epoch 9/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.5445 - my_iou_metric: 0.4795 - val_loss: 0.5007 - val_my_iou_metric: 0.5915\n",
      "\n",
      "Epoch 00009: val_my_iou_metric improved from 0.54225 to 0.59150, saving model to unet_vgg19.h5\n",
      "Epoch 10/10\n",
      "3200/3200 [==============================] - 237s 74ms/step - loss: 0.5184 - my_iou_metric: 0.4875 - val_loss: 0.4997 - val_my_iou_metric: 0.5625\n",
      "\n",
      "Epoch 00010: val_my_iou_metric did not improve from 0.59150\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "vgg19_model_depth = unet_vgg19(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(vgg19_model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg19.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 10  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = vgg19_model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWZKjRp22AFG"
   },
   "source": [
    "Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3110,
     "status": "ok",
     "timestamp": 1593350057739,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "0rIhmDls5fjD"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/My Drive/DIC/Segmantation/vgg19_model_depth.pkl', 'wb') as vgg19_model:\n",
    "    pickle.dump(vgg19_model_depth, vgg19_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBa7-e7F8ZdX"
   },
   "outputs": [],
   "source": [
    "aaaaabbbcccddeeffgghh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19069,
     "status": "ok",
     "timestamp": 1593350080270,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "UwSS-Y2lrnQH"
   },
   "outputs": [],
   "source": [
    "val_preds = vgg19_model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzeh4_IeYylM"
   },
   "source": [
    "### Threshold optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1593350084681,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "bh2QWu1T6KGj"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53790,
     "status": "ok",
     "timestamp": 1593350144155,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "MwHTfBvbYxc0",
    "outputId": "497d5d04-c2dd-4d62-8c3d-f0ac215adce7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 1/35 [00:01<00:50,  1.50s/it]\u001b[A\n",
      "  6%|▌         | 2/35 [00:02<00:49,  1.49s/it]\u001b[A\n",
      "  9%|▊         | 3/35 [00:04<00:47,  1.50s/it]\u001b[A\n",
      " 11%|█▏        | 4/35 [00:06<00:46,  1.51s/it]\u001b[A\n",
      " 14%|█▍        | 5/35 [00:07<00:45,  1.52s/it]\u001b[A\n",
      " 17%|█▋        | 6/35 [00:09<00:43,  1.52s/it]\u001b[A\n",
      " 20%|██        | 7/35 [00:10<00:42,  1.51s/it]\u001b[A\n",
      " 23%|██▎       | 8/35 [00:12<00:40,  1.51s/it]\u001b[A\n",
      " 26%|██▌       | 9/35 [00:13<00:39,  1.51s/it]\u001b[A\n",
      " 29%|██▊       | 10/35 [00:15<00:37,  1.50s/it]\u001b[A\n",
      " 31%|███▏      | 11/35 [00:16<00:36,  1.51s/it]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:18<00:34,  1.51s/it]\u001b[A\n",
      " 37%|███▋      | 13/35 [00:19<00:33,  1.51s/it]\u001b[A\n",
      " 40%|████      | 14/35 [00:21<00:31,  1.52s/it]\u001b[A\n",
      " 43%|████▎     | 15/35 [00:22<00:30,  1.52s/it]\u001b[A\n",
      " 46%|████▌     | 16/35 [00:24<00:28,  1.51s/it]\u001b[A\n",
      " 49%|████▊     | 17/35 [00:25<00:27,  1.51s/it]\u001b[A\n",
      " 51%|█████▏    | 18/35 [00:27<00:26,  1.56s/it]\u001b[A\n",
      " 54%|█████▍    | 19/35 [00:28<00:24,  1.54s/it]\u001b[A\n",
      " 57%|█████▋    | 20/35 [00:30<00:22,  1.52s/it]\u001b[A\n",
      " 60%|██████    | 21/35 [00:31<00:21,  1.51s/it]\u001b[A\n",
      " 63%|██████▎   | 22/35 [00:33<00:19,  1.52s/it]\u001b[A\n",
      " 66%|██████▌   | 23/35 [00:34<00:18,  1.52s/it]\u001b[A\n",
      " 69%|██████▊   | 24/35 [00:36<00:16,  1.52s/it]\u001b[A\n",
      " 71%|███████▏  | 25/35 [00:38<00:15,  1.55s/it]\u001b[A\n",
      " 74%|███████▍  | 26/35 [00:39<00:13,  1.54s/it]\u001b[A\n",
      " 77%|███████▋  | 27/35 [00:41<00:12,  1.54s/it]\u001b[A\n",
      " 80%|████████  | 28/35 [00:42<00:10,  1.53s/it]\u001b[A\n",
      " 83%|████████▎ | 29/35 [00:44<00:09,  1.53s/it]\u001b[A\n",
      " 86%|████████▌ | 30/35 [00:45<00:07,  1.53s/it]\u001b[A\n",
      " 89%|████████▊ | 31/35 [00:47<00:06,  1.53s/it]\u001b[A\n",
      " 91%|█████████▏| 32/35 [00:48<00:04,  1.52s/it]\u001b[A\n",
      " 94%|█████████▍| 33/35 [00:50<00:03,  1.53s/it]\u001b[A\n",
      " 97%|█████████▋| 34/35 [00:51<00:01,  1.52s/it]\u001b[A\n",
      "100%|██████████| 35/35 [00:53<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1593350152434,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "IpC3SHBuY-ku",
    "outputId": "6531e18e-8a01-45ac-f041-31facb87811b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.6380 at threshold: 0.840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.586321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.040910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.512875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.555813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.588375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.638000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.586321\n",
       "std     0.204939   0.040910\n",
       "min     0.200000   0.512875\n",
       "25%     0.370000   0.555813\n",
       "50%     0.540000   0.588375\n",
       "75%     0.710000   0.625000\n",
       "max     0.880000   0.638000"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1593350162948,
     "user": {
      "displayName": "たかちゃん",
      "photoUrl": "",
      "userId": "07604629410324899309"
     },
     "user_tz": -540
    },
    "id": "kv8HU04pZCS4",
    "outputId": "6d35855d-f564-471a-a856-854c295a9ecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f204d157978>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAIWCAYAAAClXRAXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3SUVeLG8eemE0iAQBJKgNBCMfRQxIJdrIgdsIBdF/VnwdW1rm1d3WJfFQs2iiIKrIVV7CAlQEIJBEJooSUkJCGkTWbu7w+ybogIARLeKd/POTnJvPPO5JlzYObhct97jbVWAAAAAP4nyOkAAAAAgLehJAMAAAC1UJIBAACAWijJAAAAQC2UZAAAAKAWSjIAAABQS4jTAWpr2bKlTUxMdDoGAAAA/NySJUt2WWtjD3Sf15XkxMREpaamOh0DAAAAfs4Ys+n37mO6BQAAAFALJRkAAACohZIMAAAA1OJ1c5IBAADgHVwul3JyclReXu50lKMSERGhhIQEhYaG1vkxlGQAAAAcUE5OjqKiopSYmChjjNNxjoi1Vvn5+crJyVHHjh3r/DimWwAAAOCAysvL1aJFC58tyJJkjFGLFi0OezSckgwAAIDf5csF+b+O5DVQkgEAAOC1hg4d6sjvpSQDAADAa82fP9+R31unkmyMGW6MyTTGZBlj7v+dcy43xmQYY1YZYybXui/aGJNjjHm5PkIDAAAgMDRp0kTSvgvwJkyYoOTkZPXq1UvTpk2TJH3//fc6//zzfz1//PjxmjRp0lH/3kOubmGMCZb0iqQzJeVIWmyMmWWtzahxTldJD0g6wVq72xgTV+tpnpD041GnBQAAgCP+PHuVMrYV1+tz9mwTrUcvOK5O586YMUNpaWlKT0/Xrl27NHDgQJ188sn1mqemuowkD5KUZa3NttZWSpoqaUStc26U9Iq1drckWWtz/3uHMWaApHhJ/6mfyAAAAAg0P//8s0aNGqXg4GDFx8dr2LBhWrx4cYP9vrqsk9xW0pYat3MkDa51TpIkGWPmSQqW9Ji19itjTJCkv0u6StIZRx8XAAAATqjriO+xFhISIo/H8+vt+tr4pL4u3AuR1FXSKZJGSZpojGkm6TZJX1hrcw72YGPMTcaYVGNMal5eXj1FAgAAgL846aSTNG3aNLndbuXl5enHH3/UoEGD1KFDB2VkZKiiokKFhYWaO3duvfy+uowkb5XUrsbthOpjNeVIWmitdUnaYIxZq32l+XhJJxljbpPURFKYMabEWrvfxX/W2jckvSFJKSkp9oheCQAAAPzWyJEj9csvv6hPnz4yxujZZ59Vq1atJEmXX365kpOT1bFjR/Xr169efp+x9uCd1BgTImmtpNO1rxwvljTaWruqxjnDJY2y1l5rjGkpaZmkvtba/BrnjJWUYq0df7Dfl5KSYlNTU4/w5QAAAKC+rF69Wj169HA6Rr040Gsxxiyx1qYc6PxDTrew1lZJGi9pjqTVkj6y1q4yxjxujLmw+rQ5kvKNMRmSvpM0oWZBBgAAAHxJXaZbyFr7haQvah17pMbPVtLd1V+/9xyTJE06kpAAAADAscSOewAAAEAtdRpJBgAAgO8qq3RrXtYuzV2Tqx/X5skYqW2zRkpoHqmE5o2U0LyR2jZvpHbNI9WqaYRCg/83jmqtlTHGwfRH71DX4B0IJRkAAMAPbSss07drcjV39U7NX5+viiqPGocF68SuLdUoNFhbC8s0f/0u7SguV80OGWSk1k33leZrkiMVumW7mse0UHhIkEJDghQaHKQgHyrN1lrl5+crIiLisB5HSQYAAPADHo9Vek6h5q7O1dw1uVq9fd8W0u1jIjV6cHud3j1egzrGKCxk/9m2lVUebS8q09bdZcrZXaac3aX7vheW6aUFBbqsqEztm22X0b5ibCQFBxkFBxlFhgWrcbj318mIiAglJCQc1mO8/1UBAADggPaUu/Tzun3TKL7PzNWukkoFBxkN6NBcD5zTXaf3iFPn2CYHnS4RFhKkDi0aq0OLxge83+X2aEdR+X4FemthmVZuLdKaHXs0uGOMnhqZrC5xUQ31Mh1BSQYAAPAhm/NLNXfNTn27JlcLsvPlcltFR4TolG5xOr1HnIYlxapZZFi9/b7Q4CC1i4lUu5hISS1+Pe7xWE1L3aJnvlyjc174SbcM66w/nNpFEaHB9fa7nXTIzUSONTYTAQAAvsjjsdpdWqncPRXaWVyu3D0Vyq3+XlrpPvrnt1bLc4qUlVsiSeoc21hn9IjXad3jNKBDc4UEO7No2a6SCj39+WrNWLZVHVpE6okRyTo5KdaRLIfrYJuJUJIBAAAOwuOxyt9bqdw95cotrvj1+85fv1cor7hceSUVcrl/26uaNgpVk3qat5vYMlKnd99XjBNbHnh6hFPmZ+3SQ5+tVPauvbqgTxs9fH4PxUUd3sVyxxolGQAAoA4qqzxasbVQC7ILtHBDgdbu2KNdJRWq8vy2LzWLDFV8VITiosMVV/09PipccdERiosKV3x0hGKjwv1m+kFdVFS59a/v1+vV79YrPDRI9w3vrjGD2isoyDtXw6AkAwAAHEBllUfpOYVamJ2vBdkFWrJpt8pc+6ZGJMU3Ua+2zdSq6b4SHB8drthfv4crPCRwyu/hys4r0cMzV2peVr76tmump0f2Us820U7H+g1KMgAAgPaNdKZtLtTCDQVakJ2vpZt3q9zlkSR1bxWlIZ1aaHDHGA3qGKMWTcIdTuvbrLWambZNT36eod2lLl13QqL+74wkr1oyjpIMAAACUrnLrWWbC7VwQ74WZOdr2eZCVVR5ZIzUvVW0hnSK0eCOLTSoY4xiGtffihD4n6JSl575ao2mLNqsNk0j9NiFx+ms41o5HUsSJRkAAASQzfmlmr40Rwuz87VsS6Eqq0txz9bR+40U1+cyaTi0JZsK9OCnK7Vmxx6d2TNef77wOLVp1sjRTJRkAADg9yqq3Hrjh2y99F2WqtweHdemqQZ3jNGQTi00MDFGTSNDnY4Y8Fxuj97+eYOe/2adjJHuPjNJY4cmOrZ8HSUZAAD4tV/W5+uhz1Zofd5endertR4+v6daNfXu5ccC2ZaCUj02a5XmrslVj9bRevaS3uqV0PSY5zhYSfaemdMAAACHKb+kQk9/sUafLM1Ru5hGemfcQJ3aLc7pWDiEdjGRevPaFM1ZtUOPzcpQUZnL6Ui/QUkGAAA+x+Ox+njJFv3lyzUqKa/Sbad01u2ndVWjMJZl8xXGGA1Pbq1TusV55VrSlGQAAOBT1u7co4c+XalFGws0KDFGT45MVlJ8lNOxcIS8sSBLlGQAAOAjyirdeunbdXrjx2w1iQjRs5f01qUDErx2Nzf4NkoyAADwet9l5uqRmSu1paBMl/RP0J/O7c5mH2hQlGQAAOC1dhaX6/HZGfp8xXZ1jm2sKTcO0fGdWzgdCwGAkgwAALyO22P1wYJN+tucTFW4PbrnzCTdNKyTwkO8c/4q/A8lGQAAeJWVW4v0p09XaHlOkU7q2lJPjEhWYsvGTsdCgKEkAwAAr1BaWaXn5mTq3fkbFdM4XC+O6qcLereWMVyYh2OPkgwAABxX7nJr7DuLtXhjgcYMbq8JZ3dX00ZsIw3nUJIBAICjXG6PbvtwqRZvLNDzV/TViL5tnY4EKMjpAAAAIHC5PVZ3f5Sub9fk6smLkinI8BqUZAAA4AhrrR6euVKz07fp/nO6a8zgDk5HAn5FSQYAAI7461eZmrxws247pbNuGdbZ6TjAfijJAADgmHv1+yy99sN6XTWkvSac3c3pOMBvUJIBAMAx9f6CTXr2q0yN6NtGj1+YzBJv8EqUZAAAcMzMTNuqR2au1Ond4/S3y/ooKIiCDO9ESQYAAMfENxk7dfdH6RrcMUavjOmv0GBqCLwXfzoBAECD+2V9vm6bvFTJbaL15rUDFREa7HQk4KAoyQAAoEGlbynUDe8uVoeYSE0aN0hNwtnLDN6PkgwAABrM2p17dO07ixTTJEwf3DBYzRuHOR0JqBNKMgAAaBCb80t11ZsLFRYcpA+vH6L46AinIwF1xv93AACAerezuFxj3lqgSrdHH918vNq3iHQ6EnBYGEkGAAD1avfeSl391kIVlFTq3XGDlBQf5XQk4LAxkgwAAOpNSUWVxr6zSBvzSzVp3ED1adfM6UjAEWEkGQAA1Ityl1s3vLtYK7cV69XR/TW0c0unIwFHjJIMAACOmsvt0fjJS7VwQ4H+cXkfndEz3ulIwFGhJAMAgKPi9ljd+3G6vlmdq8dHJGtE37ZORwKOGnOSAQDAEXF7rL5YsV0vzl2ndbklum94N109pIPTsYB6QUkGAACHxe2x+vfybXrp2yxl5Zaoa1wTvTK6v87r3drpaEC9oSQDAIA6cXusZqdv00vfrtP6vL1Kim+il0f307nJrRUUZJyOB9QrSjIAADioKrdHs9K36eVvs5S9a6+6t4rSq2P6a/hxrSjH8FuUZAAAcEBVbo8+S9uml79dp435perROlqvXdVfZ/WkHMP/UZIBAMB+XG6PPl22Va98l6VN+aU6rk20Xr96gM7sEU85RsCgJAMAAEn7yvGMpTl65bv12lxQquS20Zp4TYrO6BEnYyjHCCyUZAAAAlxllUefLM3RK99lKWd3mXonNNWjF6TotO6UYwQuSjIAAAGqosqtT5bsm1axtbBMfdo10xMjknVKt1jKMQIeJRkAgACzt6JKUxZt1sSfsrWzuEL92jfTUyOTNSyJcgz8FyUZAIAAUbC3UpPmb9S78zeqqMyloZ1b6G+X9dGJXVpSjoFaKMkAAPi5bYVlmvhTtqYu2qIyl1tn9YzXrad0Vr/2zZ2OBngtSjIAAH4qK7dEr/+wXp+lbZW10oi+bXXrKZ3UJS7K6WiA16MkAwDgZ5bnFOrV79ZrTsYOhYcEaczgDrrhpI5KaB7pdDTAZ1CSAQDwA9ZazV+fr1e/z9K8rHxFR4Ro/KldNHZoolo0CXc6HuBzKMkAAPgwj8fqPxk79a/vs5SeU6TYqHA9cE53jR7cXlERoU7HA3wWJRkAAB9UWeXRzLSteu2H9Vqft1cdWkTq6ZG9dHH/tooIDXY6HuDzKMkAAPiYLQWlGjVxgXJ2l6lH62i9OKqfzk1upZDgIKejAX6DkgwAgA+prPJo/OSlKi5z6Z2xA9kdD2ggdfonpzFmuDEm0xiTZYy5/3fOudwYk2GMWWWMmVx9rK8x5pfqY8uNMVfUZ3gAAALNX75crfScIj13WR+d2j2Oggw0kEOOJBtjgiW9IulMSTmSFhtjZllrM2qc01XSA5JOsNbuNsbEVd9VKukaa+06Y0wbSUuMMXOstYX1/koAAPBzc1bt0DvzNmrs0ESdfVwrp+MAfq0uI8mDJGVZa7OttZWSpkoaUeucGyW9Yq3dLUnW2tzq72utteuqf94mKVdSbH2FBwAgUGwpKNWEj9PVq21TPXBud6fjAH6vLiW5raQtNW7nVB+rKUlSkjFmnjFmgTFmeO0nMcYMkhQmaf2RhgUAIBBVVnl0+5RlslZ6ZXR/hYewegXQ0Orrwr0QSV0lnSIpQdKPxphe/51WYYxpLel9Sddaaz21H2yMuUnSTZLUvn37eooEAIB/eG7OGqVtKdSrY/qrfQt2zQOOhbqMJG+V1K7G7YTqYzXlSJplrXVZazdIWqt9pVnGmGhJn0t60Fq74EC/wFr7hrU2xVqbEhvLbAwAAP5r7uqdmvjTBl09pIPO7dXa6ThAwKhLSV4sqasxpqMxJkzSlZJm1TrnM+0bRZYxpqX2Tb/Irj7/U0nvWWun11tqAAACwLbCMt3zcbp6to7Wg+f1cDoOEFAOWZKttVWSxkuaI2m1pI+stauMMY8bYy6sPm2OpHxjTIak7yRNsNbmS7pc0smSxhpj0qq/+jbIKwEAwI+43PvmIbuqPHplTH920QOOMWOtdTrDflJSUmxqaqrTMQAAcNQzX67Raz+s14uj+unCPm2cjgP4JWPMEmttyoHuY/9KAAC8zHeZuXrth/UaNag9BRlwCCUZAAAvsqOoXPd8lK7uraL06AU9nY4DBCxKMgAAXqLK7dEdU5ap3OVmHjLgsPpaJxkAABylf36zVos2FuifV/RR59gmTscBAhojyQAAeIEf1+bp1e/X6/KUBI3sl+B0HCDgUZIBAHDYzuJy3TUtTV3jmujPFyY7HQeAmG4BAICj3B6rO6cuU2mlW1NH91ejMOYhA96AkgwAgINemLtOC7IL9NylvdU1PsrpOACqMd0CAACHzMvapZe+XaeL+7fVZSntnI4DoAZKMgAADsjdU647p6apU8vGemIE85ABb8N0CwAAjjG3x+quaWnaU+7SBzcMUuNwPo4Bb8PfSgAA6qBgb6UKSyvVPDJM0Y1CFRxkjvi5XvkuS/Oy8vXMxb3UvVV0PaYEUF8oyQAAHMK6nXs04pV5Kq10S5KMkZo2ClXzyDA1i9z/e/PIUDWLDNv/58b77osIDdaC7Hw9/81ajejbRlcMZB4y4K0oyQAAHES5y607pqYpIjRYj49IVnGZS4Wlldpd6tLu0koVlrq0s7hcmTv2aHdp5a9F+kAahQbLba0SWzTWUyN7yZgjH40G0LAoyQAAHMSzX2Vq9fZivT02Rad1jz/k+eUut4rKXCrYW/lrif71+95KlVe5Ne6EjmrCPGTAq/E3FACA3/FdZq7enrdBY4cm1qkgS1JEaLAiQoMVHx3RwOkANCSWgAMA4ADy9lRowsfp6hYfpfvP6e50HADHGCPJAADU4vFY3ftxuvaUV2nyjUMUEcpW0UCgYSQZAIBa3pm/UT+szdND5/dUEltFAwGJkgwAQA2rthXpr1+u0Rk94nXV4PZOxwHgEEoyAADVyirdumPKMjWLDNWzl/ZmiTYggDEnGQCAao//O0PZu/bqg+sHK6ZxmNNxADiIkWQAACR9tXK7pizarJtO7qQTurR0Og4Ah1GSAQABb3tRmf74yQr1Tmiqe87s5nQcAF6AkgwACGhuj9Vd09Lkcnv0wpX9FBbCRyMA5iQDAALcaz+s14LsAj13aW91bNnY6TgAvAT/XAYABKxlm3frH1+v1fm9W+vSAQlOxwHgRSjJAICAtKfcpTunpqlVdISeGtmL5d4A7IfpFgCAgPTozFXK2V2qj24+Xk0bhTodB4CXYSQZABBwPlu2VTOWbdUdp3dVSmKM03EAeCFKMgAgoGzOL9VDn61USofmGn9qF6fjAPBSlGQAQMBwuT26c9oyGSM9f2VfhQTzMQjgwJiTDAAIGC/OXadlmwv18uh+Smge6XQcAF6Mf0IDAALCgux8vfxdli4bkKDze7dxOg4AL0dJBgD4vaJSl+6alqbEFo312IXHOR0HgA9gugUAwK9Za/XAp8u1q6RCM249QY3D+egDcGiMJAMA/NrUxVv0xYoduvesbuqV0NTpOAB8BP+cBgD4pcLSSj3z5RpNXbxFJ3ZpqRtP6uR0JAA+hJIMAPAr1lrNWLpVT32xWkVlLt10cif93xldFRTEttMA6o6SDADwG+vzSvTQpyv1S3a++rVvpqdH9lKP1tFOxwLggyjJAACfV+5y69Xv1+u179crIjRIT41M1qiB7Rk9BnDEKMkAAJ/287pdenjmSm3YtVcj+rbRQ+f1VGxUuNOxAPg4SjIAwCfl7anQU59n6LO0bUpsEan3rx+kk7rGOh0LgJ+gJAMAfIrHYzV18RY98+Vqlbs8uuP0rrrtlM6KCA12OhoAP0JJBgD4jNXbi/Xgpyu0dHOhhnSK0ZMX9VKXuCZOxwLghyjJAACvV1pZpRe+Wac3f96gpo1C9ffL+uji/m1lDBfmAWgYlGQAgFebu3qnHpm5SlsLy3TlwHb64/Duat44zOlYAPwcJRkA4JW2F5XpsVmrNGfVTiXFN9HHtxyvgYkxTscCECAoyQAAr7M+r0RXvrFAe8pdum94N91wYieFhQQ5HQtAAKEkAwC8yoZdezXqjQWy1mrW+BOVFB/ldCQAAYiSDADwGpvzSzV64gJVeaym3DiEggzAMfzfFQDAK2wpKNWoiQtU5nLrg+sHq1srCjIA51CSAQCO21pYplET981B/uD6werZJtrpSAACHNMtAACO2l5UptETF6iozKUPbxis5LZNnY4EAIwkAwCcs7O4XKMnLlR+SaXeu26Qeic0czoSAEiiJAMAHJK7p1yjJy5QbnG53r1uoPq1b+50JAD4FdMtAADH3K6SCo2ZuFDbCsv17nWDNKADm4QA8C6MJAMAjqmCvZW66s2F2rK7VG+PHahBHSnIALwPJRkAcMwUllZqzJsLtWHXXr117UAd37mF05EA4ICYbgEAOCaKSl266q2FWp9XojevSdEJXVo6HQkAfhcjyQCABldc7tI1by/U2h0lev2qATo5KdbpSABwUJRkAECD2lPu0rVvL1LG9mK9Oqa/Tu0e53QkADgkSjIAoMHsrajSuHcWa0VOkV4a1V9n9Ix3OhIA1EmdSrIxZrgxJtMYk2WMuf93zrncGJNhjFlljJlc4/i1xph11V/X1ldwAIB3K62s0rhJi7VsS6FeHNVPw5NbOR0JAOrskBfuGWOCJb0i6UxJOZIWG2NmWWszapzTVdIDkk6w1u42xsRVH4+R9KikFElW0pLqx+6u/5cCAPAWZZVuXT8pVakbC/TClf10bq/WTkcCgMNSl5HkQZKyrLXZ1tpKSVMljah1zo2SXvlv+bXW5lYfP1vS19bagur7vpY0vH6iAwC8UbnLrRvfS9WCDfn6x+V9dUGfNk5HAoDDVpeS3FbSlhq3c6qP1ZQkKckYM88Ys8AYM/wwHitjzE3GmFRjTGpeXl7d0wMAvM6E6cs1b/0uPXdpH13U7zdv+QDgE+rrwr0QSV0lnSJplKSJxphmdX2wtfYNa22KtTYlNpZlgQDAV32TsVOz07fprjOSdOmABKfjAMARq0tJ3iqpXY3bCdXHasqRNMta67LWbpC0VvtKc10eCwDwA3srqvTIzJVKim+iW4Z1djoOAByVupTkxZK6GmM6GmPCJF0paVatcz7TvlFkGWNaat/0i2xJcySdZYxpboxpLums6mMAAD/z9/+s1baicv3l4l4KC2GFUQC+7ZCrW1hrq4wx47Wv3AZLettau8oY87ikVGvtLP2vDGdIckuaYK3NlyRjzBPaV7Ql6XFrbUFDvBAAgHNW5BRp0vwNumpIew3oEON0HAA4asZa63SG/aSkpNjU1FSnYwAA6qjK7dGIV+Ypb0+FvrlnmKIjQp2OBAB1YoxZYq1NOdB9hxxJBgDgYN6Zt1Grtu3bcpqCDMBfMGkMAHDEthSU6h9fr9Xp3eN0DjvqAfAjlGQAwBGx1uqRmStljPT4RckyxjgdCQDqDSUZAHBEPl+xXd9l5unuM5PUtlkjp+MAQL2iJAMADltRmUt/np2h5LbRGjs00ek4AFDvuHAPAHDY/vrVGuWXVOidsQMVEsx4CwD/wzsbAOCwLN5YoMkLN+u6EzoquW1Tp+MAQIOgJAMA6qyyyqM/zVihts0a6a4zk5yOAwANhukWAIA6e/2H9VqXW6K3x6aocTgfIQD8FyPJAIA6yc4r0UvfZem8Xq11Wvd4p+MAQIOiJAMADslaqwc/XanwkCA9ekFPp+MAQIOjJAMADumTpVv1S3a+7j+nu+KiI5yOAwANjpIMADio/JIKPfV5hlI6NNeoge2djgMAxwQlGQBwUE99vlolFVV6+uJeCgpi62kAgYGSDAD4XT+v26UZy7bq5pM7Kyk+yuk4AHDMUJIBAAdU7nLrwc9WKLFFpMaf1sXpOABwTLHIJQDggF76dp025ZfqwxsGKyI02Ok4AHBMMZIMAPiNzB179PoP2bq4f1ud0KWl03EA4JijJAMA9uPxWD0wY7miIkL00HmsiQwgMFGSAQD7+XDRZi3dXKiHzuupmMZhTscBAEdQkgEAv9pZXK5nv1yjE7q00MX92zodBwAcQ0kGAPzqz7NXqcLt0ZMX9ZIxrIkMIHBRkgEAkqSZaVv1xYoduuO0LurYsrHTcQDAUSwBBwABbk+5S09/sVpTFm1R74Smuunkzk5HAgDHUZIBIID9vG6X/vjJcm0vKtPNwzrprjOSFBbCfzICACUZAAJQSUWVnv5itSYv3KxOsY01/dah6t++udOxAMBrUJIBIMDMz9qlCdOXa1tRmW48qaPuOasbO+oBQC2UZAAIEHsrqvTMl2v0/oJN6tiysT6++XilJMY4HQsAvBIlGQACwILsfE2Ynq6c3WW6/sSOuvesbmoUxugxAPweSjIA+LHSyio9+1WmJs3fqMQWkfro5uM1kNFjADgkSjIA+KlFGwo0YXq6NuWXatwJibrv7O6MHgNAHVGSAcDPlFW69dycTL0zf4PaNY/U1JuGaEinFk7HAgCfQkkGAD+SurFAE6Yv14Zde3Xt8R30x3O6KzKMt3oAOFy8cwKAHyh3ufW3OZl6a94GtW3WSJNvHKyhnVs6HQsAfBYlGQB83JJNBZrw8XJl79qrq4a01wPn9FDjcN7eAeBo8C4KAD6qpKJKz321Ru8t2KQ2TRvpwxsG64QujB4DQH2gJAOAD/ouM1cPfbpS24rKdO3xiZpwdjdGjwGgHvGOCgA+pGBvpZ74d4Y+XbZVXeKaaPotQzWgQ3OnYwGA36EkA4APsNZqVvo2/Xl2hvaUu3TH6V31h1M7KzyEdY8BoCFQkgHAy20rLNNDn63Ut2ty1addMz17SW91axXldCwA8GuUZADwUh6P1YeLNuuvX66R22P18Pk9NXZoooKDjNPRAMDvUZIBwAutzyvRA5+s0KKNBTqxS0v95eJeahcT6XQsAAgYlGQA8CIut0dv/JitF+auU6PQYD13aW9dOiBBxjB6DADHEiUZALzE8pxC/fGTFVq9vVjn9WqtRy/sqbioCKdjAUBAoiQDgMPKKt365zdr9eZP2WrZJFyvXz1AZx/XyulYABDQKMkA4KD5Wbv0wKcrtCm/VKMGtdP95/RQ00ahTscCgIBHSQYAh0xeuFl/+nSFEltEavKNgzW0M1tKA4C3oCQDgAOW5xTqsVmrNCwpVq9dNUCNwtgUBAC8SZDTAQAg0BSVunTbh0vVsu55OtgAACAASURBVEmYnr+iLwUZALwQI8kAcAxZa3Xv9HTtLC7XtJuPV/PGYU5HAgAcACPJAHAMTfwpW19n7NQD5/RQ//bNnY4DAPgdlGQAOEZSNxbor19l6pzkVhp3QqLTcQAAB0FJBoBjIL+kQuMnL1O75o3010t7s4MeAHg55iQDQANze6z+b1qaCkor9eltQxUdwTrIAODtGEkGgAb28rdZ+mndLj1+4XE6rk1Tp+MAAOqAkgwADejndbv0/Ny1urhfW10xsJ3TcQAAdURJBoAGsqOoXHdOXaYusU305Mhk5iEDgA+hJANAA6hye3T7lKUqc7n1r6v6KzKMS0AAwJfwrg0ADeC5/2Rq8cbdeuHKvuoSF+V0HADAYWIkGQDq2dcZO/X6D9kaM7i9RvRt63QcAMARoCQDQD3aUlCqez5KU3LbaD18fk+n4wAAjhAlGQDqSUWVW3+YvFRW0qujBygiNNjpSACAI1SnkmyMGW6MyTTGZBlj7j/A/WONMXnGmLTqrxtq3PesMWaVMWa1MeZFw+XdAPzU05+v1vKcIv3tsj5q3yLS6TgAgKNwyAv3jDHBkl6RdKakHEmLjTGzrLUZtU6dZq0dX+uxQyWdIKl39aGfJQ2T9P1R5gYArzI7fZve/WWTbjixo84+rpXTcQAAR6kuI8mDJGVZa7OttZWSpkoaUcfnt5IiJIVJCpcUKmnnkQQFAG+1Pq9E93+yXP3bN9Mfz+nudBwAQD2oS0luK2lLjds51cdqu8QYs9wYM90Y006SrLW/SPpO0vbqrznW2tW1H2iMuckYk2qMSc3LyzvsFwEATimrdOsPHy5VWEiQXh7dX6HBXOoBAP6gvt7NZ0tKtNb2lvS1pHclyRjTRVIPSQnaV6xPM8acVPvB1to3rLUp1tqU2NjYeooEAA3vkZkrlblzj56/sp/aNGvkdBwAQD2pS0neKqldjdsJ1cd+Za3Nt9ZWVN98U9KA6p9HSlpgrS2x1pZI+lLS8UcXGQC8w0epW/TxkhzdfmoXDUviH/gA4E/qUpIXS+pqjOlojAmTdKWkWTVPMMa0rnHzQkn/nVKxWdIwY0yIMSZU+y7a+810CwDwNau3F+vhz1ZqaOcWuvOMJKfjAADq2SFXt7DWVhljxkuaIylY0tvW2lXGmMclpVprZ0m6wxhzoaQqSQWSxlY/fLqk0ySt0L6L+L6y1s6u/5cBAMfOnnKX/vDhUjVtFKoXruyn4CBWtgQAf2OstU5n2E9KSopNTU11OgYAHFC5y63rJi3Wwg0F+vCGwRrSqYXTkQAAR8gYs8Ram3Kg+7gMGwDqyO2xumtamuavz9ffLutNQQYAP0ZJBoA6sNbqoc9W6suVO/Tw+T01sl+C05EAAA2IkgwAdfCPr9dqyqLNuu2Uzrr+xI5OxwEANDBKMgAcwjvzNuilb7N05cB2mnB2N6fjAACOAUoyABzEZ8u26s+zM3T2cfF68qJkGcNKFgAQCCjJAPA7vsvM1b0fp2tIpxi9cGU/hbDlNAAEDN7xAeAAlmzarVs/WKJuraI08ZoURYQGOx0JAHAMUZIBoJa1O/foukmL1So6QpPGDVJURKjTkQAAxxglGQBqyNldqmveWqSwkCC9f/1gxUaFOx0JAOAASjIAVMsvqdA1by3S3soqvXfdILWLiXQ6EgDAIZRkAJBUUlGlcZMWa2thmd66dqB6tI52OhIAwEEhTgcAAKdVVLl18/upWrWtWK9fNUCDOsY4HQkA4DBGkgEENLfH6q5paZqXla+/XtJbZ/SMdzoSAMALUJIBBCxrrR6ZuVJfrNihB8/toUsHJDgdCQDgJSjJAALWP79Zpw8XbtbNwzrpxpM7OR0HAOBFKMkAAtKkeRv04tx1umxAgu4f3t3pOAAAL0NJBhBwZqZt1WOzM3RGj3j95eJeMsY4HQkA4GUoyQACyg9r83TPR+ka1DFGL4/up5Bg3gYBAL/FpwOAgLFu5x7d8v4SdY2P0pvXpigiNNjpSAAAL0VJBhAQqtwe3Tt9uSJCg/TuuIGKjgh1OhIAwIuxmQiAgPDWzxuUvqVQL47qp7joCKfjAAC8HCPJAPze+rwS/f3rtTqrZ7wu6N3a6TgAAB9ASQbg19weq/umL1ej0GA9OTKZlSwAAHVCSQbg1ybN36glm3br0Qt6Ki6KaRYAgLqhJAPwWxt37dVzc9botO5xGtmvrdNxAAA+hJIMwC95PFb3fbJcocFBenokG4YAAA4PJRmAX3p/wSYt2lCgh8/rqVZNmWYBADg8lGQAfmdLQan++tUanZwUq8tSEpyOAwDwQZRkAH7FWqs/frJcQcboLxczzQIAcGQoyQD8yuRFmzV/fb7+dG4PtW3WyOk4AAAfRUkG4De2FpbpL1+s0QldWmjUoHZOxwEA+DBKMgC/YK3V/Z8sl8daPXNxb6ZZAACOCiUZgF/4KHWLflq3S/ef013tYiKdjgMA8HGUZAA+b3tRmZ7892oN7hijqwZ3cDoOAMAPUJIB+DRrrf40Y4VcHo/+eklvBQUxzQIAcPQoyQB82oylW/VdZp4mnN1diS0bOx0HAOAnKMkAfFZucbn+PHuVUjo019ihiU7HAQD4EUoyAJ9krdWDn61URZVHz17aW8FMswAA1CNKMgCfNCt9m77O2Kl7zkpSp9gmTscBAPgZSjIAn5O3p0KPzVqlvu2a6foTOzkdBwDghyjJAHzOo7NWam+FW88xzQIA0EAoyQB8yufLt+uLFTt05xld1TU+yuk4AAA/RUkG4DPySyr0yMyV6tW2qW4+mWkWAICGE+J0AAD+q7LKo7fnbVBpRZVioyMUHxWuuOgIxUWFKzYqXKHBh/fv9MdmZ6i43KUPLxuskMN8LAAAh4OSDKBBFOyt1C0fLNGiDQUKMpLH7n+/MVJMZNivpTkuKlzx0RGKi973c80yHR4SrDmrdmh2+jbdfWaSureKduZFAQACBiUZQL3Lyi3R9e8u1vaicr1wZV+d16u18vdWKre4QjuLy5W7p0K5e8q1s7hCedXf1+wo1q6SSrlrt2lJzSNDVe7yqGfraN16SmcHXhEAINBQkgHUq5/X7dKtHy5ReEiQptw4RAM6NJckxUdHKD46Qr3U9Hcf6/ZY5e+tUG7xvhK97/u+Yl1Y6tKdZ3Q97CkaAAAcCUoygHrz4cJNemTmKnWJbaI3r01Ru5jIw3p8cJBRXFSE4qIipIOUaQAAGholGcBRc3usnvp8td6et0GndIvVS6P6KSoi1OlYAAAcMUoygKNSUlGlO6Ys07drcjXuhEQ9eG4PVp4AAPg8SjKAI5azu1Q3vJuqdbkleuKiZF09pIPTkQAAqBeUZABHZOnm3brpvVRVVHk0adxAndQ11ulIAADUG0oygMM2K32b7v04Xa2iIzT1phR1iWN7aACAf6EkA6gza61emLtOz3+zToMSY/Ta1QMU0zjM6VgAANQ7SjKAOil3uXXf9OWalb5Nl/RP0NMXJys8JNjpWAAANAhKMoBDyttToZveT9WyzYW6b3g33Tqss4wxTscCAKDBUJIBHNSaHcW6flKq8vdW6F9j+uucXq2djgQAQIOjJAP4Xd+u2anbJy9T4/AQfXzzUPVKYBc8AEBgoCQD+A1rrd6et1FPfZ6hHq2j9ea1KWrdtJHTsQAAOGYoyQD2U+5y608zVmjGsq06q2e8nr+yryLDeKsAAAQWPvkA/GpLQalu+WCJVm0r1l1nJOn207ooKIgL9AAAgYeSDECSNC9rl8ZPXqoqj9Vb16bo9B7xTkcCAMAxQXU5yRgz3BiTaYzJMsbcf4D7xxpj8owxadVfN9S4r70x5j/GmNXGmAxjTGL9xQdwtKy1ev2H9br6rYVq2SRcs8afSEEGAAS8Q44kG2OCJb0i6UxJOZIWG2NmWWszap06zVo7/gBP8Z6kp6y1XxtjmkjyHG1oAPWjtLJKE6Yv1+fLt+vcXq303KV91Dic/2ACAKAun4aDJGVZa7MlyRgzVdIISbVL8m8YY3pKCrHWfi1J1tqSo8gKoB5t3LVXN7+/ROty9+iPw7vrlmGd2CAEAIBqdZlu0VbSlhq3c6qP1XaJMWa5MWa6MaZd9bEkSYXGmBnGmGXGmOeqR6b3Y4y5yRiTaoxJzcvLO+wXAeDwfJeZqwtf/lk795Tr3esG6dZT2EEPAICa6jQnuQ5mS0q01vaW9LWkd6uPh0g6SdK9kgZK6iRpbO0HW2vfsNamWGtTYmNj6ykSgNo8HquX5q7TdZMWq23zSM0ef6JO6srfOQAAaqtLSd4qqV2N2wnVx35lrc231lZU33xT0oDqn3MkpVlrs621VZI+k9T/6CIDOBJ7yl265YMl+vvXazWiTxvNuHWo2sVEOh0LAACvVJc5yYsldTXGdNS+cnylpNE1TzDGtLbWbq++eaGk1TUe28wYE2utzZN0mqTUekkOoM6yckt08/up2phfqkfO76lxJyQyvQIAgIM4ZEm21lYZY8ZLmiMpWNLb1tpVxpjHJaVaa2dJusMYc6GkKkkFqp5SYa11G2PulTTX7PtEXiJpYsO8FAAHMmfVDt3zUbrCQ4L0wfWDdXznFk5HAgDA6xlrrdMZ9pOSkmJTUxlsBo6W22P1/Ddr9dK3WeqT0FT/umqA2jRr5HQsAAC8hjFmibU25UD3sSAq4IeKSl26c9oyfZ+Zp8tTEvT4iGRFhP5mYRkAAPA7KMmAl9hVUqG1O/cc9fOUVrj1xOcZ2lZYpicvStaYwe2ZfwwAwGGiJANeYHb6Nv3p0xXaU15VL88XFxWuqTcdrwEdmtfL8wEAEGgoyYCD9lZU6bFZq/Txkhz1a99Md52RpLCQo1++vEeraDWNDK2HhAAABCZKMuCQ5TmFunNqmjbm79Xtp3XRHad3VWhwfe3vAwAAjgYlGTjGPB6rN37K1t/mZCo2KlxTbhyiIZ1Ylg0AAG9CSQaOoZ3F5br7ozTNy8rXOcmt9JeLe6lZZJjTsQAAQC2UZOAY+Tpjp+6bnq5yl0fPXNxLVwxsx6oTAAB4KUoy0MDKXW499flqvb9gk3q2jtaLo/qpS1wTp2MBAICDoCQDDWjNjmLdMWWZ1u4s0Y0nddS9Z3dTeAibegAA4O0oyUADsNbqvV826akvVis6IlTvXjdIw5JinY4FAADqiJIM1LP8kgrdN3255q7J1andYvXcZX3Uskm407EAAMBhoCQD9eindXm6+6N0FZW69OgFPTV2aCIX5wEA4IMoyUA9qKzy6G//ydQbP2arS1wTvXfdIPVoHe10LAAAcIQoycBR2rhrr26fskwrthZpzOD2eui8nmoUxsV5AAD4MkoycBRyi8s1euIClbrcev3qATr7uFZORwIAAPWAkgwcodLKKt3wXqoKy1z66Objldy2qdORAABAPQlyOgDgi9weq/+bmqaVW4v04pX9KMgAAPgZSjJwBJ75crX+k7FTD5/fU2f0jHc6DgAAqGeUZOAwfbBgkyb+tEHXHt9B407o6HQcAADQACjJwGH4PjNXj85apdO6x+nh83s6HQcAADQQSjJQR2t2FGv85GVKio/Si6P6KSSYvz4AAPgrPuWBOsgtLtd17yxW4/BgvT02RU3CWRgGAAB/xic9cAillVW6/t3/LfXWumkjpyMBAIAGxkgycBBuj9WdU9O0ahtLvQEAEEgoycBB/OWL1fqapd4AAAg4lGTgd7y/YJPe/Jml3gAACESUZOAAvs/M1WMs9QYAQMCiJAO1rN7OUm8AAAQ6Pv2BGnYWl+u6SSz1BgBAoKMBANX2LfW2WEUs9QYAQMBjJBnQ/5Z6y9hWrJdGsdQbAACBjpIMSHq6xlJvp/dgqTcAAAIdJRkB7/1fNuqtnzdo7NBElnoDAACSKMkIcN9l5upRlnoDAAC1UJIRsDK2FWv8h0vVvVW0XhrVT8FBxulIAADAS1CSEZDW55XomrcXKioiVG+NTVFjlnoDAAA1UJIRcLYUlGrMxIWyVvrghsEs9QYAAH6D4TMElO1FZRo1cYHKXG5NvWmIusQ1cToSAADwQowkI2Dk7anQmIkLVVjq0nvXDVKP1tFORwIAAF6KkoyAsHtvpa56c6G2F5XrnXED1addM6cjAQAAL8Z0C/i94nKXrnl7kTbk79U7YwdqYGKM05EAAICXYyQZfm1vRZXGvbNYa3YU67Wr+uuELi2djgQAAHwAJRl+q9zl1g3vpmrZ5t164cp+Oq07200DAIC6YboF/FJFlVu3fLBECzbk6x+X99G5vVo7HQkAAPgQRpLhd6rcHt05JU3fZ+bpqYt6aWS/BKcjAQAAH0NJhl9xe6zu+ThdX63aoUfO76nRg9s7HQkAAPggSjL8hrVWD366QjPTtmnC2d103YkdnY4EAAB8FCUZfsFaqz/PztDUxVs0/tQu+sOpXZyOBAAAfBglGT7PWqtn52Rq0vyNuv7EjrrnrCSnIwEAAB9HSYbPe/nbLP3r+/UaM7i9Hjqvh4wxTkcCAAA+jpIMn/bmT9n6+9drdXH/tnpiRDIFGQAA1AtKMnzW+ws26cnPV+u8Xq317CW9FRREQQYAAPWDkgyfNH1Jjh7+bKXO6BGnf17RVyHB/FEGAAD1h2YBnzN9SY7um56uk7q21Muj+ysshD/GAACgfrEtNXyGtVYvzF2n579ZpxO7tNTrVw9QRGiw07EAAIAfoiTDJ1RWeXT/jOWasXSrLh2QoKdH9mIEGQAANBhKMrxeUZlLt7y/RL9k5+vuM5N0+2ldWMUCAAA0KEoyvNqWglJdN2mxNubv1T+v6KOR/RKcjgQAAAIAJRlea3lOoa6blKqKKrfevW6QhnZu6XQkAAAQICjJ8ErfZOzU7VOWKaZxmKbcOFhd46OcjgQAAAIIJRle571fNuqxWauU3Lap3rw2RXFREU5HAgAAAaZOywMYY4YbYzKNMVnGmPsPcP9YY0yeMSat+uuGWvdHG2NyjDEv11dw+B+Px+rJf2fokZmrdFr3eE29aQgFGQAAOOKQI8nGmGBJr0g6U1KOpMXGmFnW2oxap06z1o7/nad5QtKPR5UUfq3c5db/TU3TV6t2aOzQRD18fk8Fs800AABwSF2mWwySlGWtzZYkY8xUSSMk1S7JB2SMGSApXtJXklKOMCf82K6SCt34XqrSthTq4fN76voTOzodCQAABLi6TLdoK2lLjds51cdqu8QYs9wYM90Y006SjDFBkv4u6d6D/QJjzE3GmFRjTGpeXl4do8MfrM8r0cWvzlfGtmL9a8wACjIAAPAK9bVl2WxJidba3pK+lvRu9fHbJH1hrc052IOttW9Ya1OstSmxsbH1FAnebtGGAl386nztrajS1JuGaHhyK6cjAQAASKrbdIutktrVuJ1QfexX1tr8GjfflPRs9c/HSzrJGHObpCaSwowxJdba31z8h8AyK32b7v0oXQkxjTRp7CC1bxHpdCQAAIBf1aUkL5bU1RjTUfvK8ZWSRtc8wRjT2lq7vfrmhZJWS5K1dkyNc8ZKSqEgBzZrrf71w3o9+1WmBnWM0RtXD1CzyDCnYwEAAOznkCXZWltljBkvaY6kYElvW2tXGWMel5RqrZ0l6Q5jzIWSqiQVSBrbgJnho1xujx6ZuVJTFm3RhX3a6LnLeis8JNjpWAAAAL9hrLVOZ9hPSkqKTU1NdToG6llWbonumpamFVuLNP7ULrr7zCQFscQbAABwkDFmibX2gKuvseMeGpTHY/X+gk16+ovVigwL1r/G9Nc5vVo7HQsAAOCgKMloMDuKyjVherp+WrdLp3SL1bOX9FZcNDvoAQAA70dJRoP49/JtevDTlaqs8ujJi5I1ZnB7GcP0CgAA4BsoyahXRWUuPTpzpT5L26Y+7Zrpn5f3UafYJk7HAgAAOCyUZNSbeVm7dO/H6crdU6G7z0zSbad0Vkhwfe1XAwAAcOxQknHUyl1uPftVpt6et0GdWjbWjFuHqk+7Zk7HAgAAOGKUZByVlVuLdNe0NK3LLdG1x3fQ/ef0UKMw1j4GAAC+jZKMI+L2WL32w3o9/81aNY8M07vXDdKwpFinYwEAANQLSjIO2+b8Ut39UZpSN+3Web1a68mLktW8MVtLAwAA/0FJRp1Za/VR6hY9PjtDQUFGz1/RVyP6tmFpNwAA4HcoyaiTvD0VemDGcn2zOldDO7fQ3y7rozbNGjkdCwAAoEFQknFIC7PzdduHS7WnokoPn99T44YmKiiI0WMAAOC/KMk4qJlpWzXh4+VKiGmkyTcOUbdWUU5HAgAAaHCUZByQtVavfr9ez83J1KCOMXrj6gFqFsnFeQAAIDBQkvEbLrdHD3+2UlMXb9GIvm307KW9FR7C2scAACBwUJKxnz3lLv1h8jL9uDZPt5/WRXefmcTqFQAAIOBQkvGr7UVlGvfOYq3LLdFfL+mlKwa2dzoSAACAIyjJkCSt2lak6yYt1t4Kt94ZO1Ans3seAAAIYJRk6PvMXP3hw6WKbhSqj285Xj1aRzsdCQAAwFGU5AA3ZdFmPfTZSnWLj9LbYweqVdMIpyMBAAA4jpIcoDweq7/9J1Ovfr9ew5Ji9cqY/moSzh8HAAAAiZIckMpdbk2Yvlyz07dp1KD2emLEcQoJDnI6FgAAgNegJAeY3XsrddP7qVq8cbfuP6e7bj65E0u8AQAA1EJJDiCb8vdq3DuLlVNYppdG9dMFfdo4HQkAAMArUZIDxNLNu3XDu6nyWKsPbxisgYkxTkcCAADwWpTkAPDliu36v2lpatU0QpPGDVLHlo2djgQAAODVKMl+7s2fsvXUF6vVr10zTbwmRS2ahDsdCQAAwOtRkv3Yz+t26cnPV+uc5Fb65xV9FREa7HQkAAAAn0BJ9lPWWj03Z43aNmuk56/sq/AQCjIAAEBdsTiun/pPxk6l5xTpzjO6UpABAAAOEyXZD7k9Vn//T6Y6xTbWxf3aOh0HAADA51CS/dCs9K1au7NE95zZjZ30AAAAjgANys9UVnn0z6/X6bg20TonuZXTcQAAAHwSJdnPfJS6RZsLSnXv2d0UFMR20wAAAEeCkuxHyl1uvTh3nQYmNtcp/9/evUdbWdd5HH9/AQHlqh5QChUUkFBRkZgcG/OS6ThFJY6XapRWpaVWK8pyJmfNTDWzKrqtabRJHafUkhQ16TJDVpLKaHEVBQQRUS4pNwEFuX/nj7OdOe5QnoOc/bD3eb/W2ot9eTb7c7486+HDj2fvPaRP2XEkSZLqliW5gdzy8BJWvriFq88eSoSryJIkSXvKktwgXty8jeunPMU7hvRh1MCDyo4jSZJU1yzJDeKmB59m3aZtfO5dR5cdRZIkqe5ZkhvA2o1buenBxZx73KEc179X2XEkSZLqniW5AXxvyiJe3raDcWcNKTuKJElSQ7Ak17k/rn+ZHz78DOeN6M+gvj3KjiNJktQQLMl17ru/XURm8ukzB5cdRZIkqWFYkuvYktUbuWPaUj4w6nAOO+iAsuNIkiQ1DEtyHfvOrxfSqWNw5RmDyo4iSZLUUCzJdeqJ5zZw76Mr+PApA+nbo2vZcSRJkhqKJblOffNXC+nepROXn3pk2VEkSZIajiW5Ds169gXum/c8l596JL0P6Fx2HEmSpIZjSa5D3/jVAg7u1pkPnzKw7CiSJEkNyZJcZ6YuWs3URWu44vRBdOvSqew4kiRJDcmSXEcyk/GTF9CvV1c++GeHlx1HkiSpYVmS68iv569k9tJ1fPrMwXTdr2PZcSRJkhqWJblO7NyZfGPyAgY2dWPMSf3LjiNJktTQLMl14mdzVrDg+Rf5zFlD2K+jf2ySJEltybZVB7bt2Mm37lvI0EN78O7j+pUdR5IkqeFZkuvAndOX8cyaTVx99tF06BBlx5EkSWp4luR93OZtO/jX3zzJiMN7c8bQvmXHkSRJahcsyfu42x55huc2bObqs4cS4SqyJElSLViS92EvbdnO9VOe4i8GN3HyUQeXHUeSJKndsCTvw25+6GnWbtzK5951dNlRJEmS2hVL8j7qhY1bufGBxZx9zCEcf1jvsuNIkiS1K5bkfdS/P/AUL23dzmddRZYkSao5S/I+6InnNvCDqUt4/wlvZsghPcqOI0mS1O4UKskRcU5ELIiIRRFxzS4eHxsRqyJiduXy0cr9J0TEwxExNyLmRMSFe/sHaDTrNm3lsltm0Gv//bjmL4eWHUeSJKld6rS7DSKiI3AdcBawDJgWEZMyc17Vpj/JzKuq7tsEXJKZT0bEm4AZETE5M9ftjfCNZvuOnXzy9lk8t34zEy5/G317di07kiRJUrtUZCV5FLAoMxdn5lZgAvDeIr95Zi7MzCcr11cAK4E+exq20X198gIefHI1X3nfsYw4/MCy40iSJLVbRUrym4GlLW4vq9xXbUzllIqJEXFY9YMRMQroDDy1i8cui4jpETF91apVBaM3lntnL+eGBxZzyclHcMFb/2R8kiRJqqG99ca9nwEDMnM4cB/ww5YPRkQ/4Fbgw5m5s/rJmXlDZo7MzJF9+rS/hebHl6/n8xPnMGrgQfz9u4eVHUeSJKndK1KSlwMtlzb7V+77P5m5JjO3VG7eBJz0ymMR0RP4BfDFzHzkjcVtPKtf2sJlt0zn4G6duf6DI9ivox84IkmSVLYijWwaMDgiBkZEZ+AiYFLLDSorxa8YDcyv3N8ZuAe4JTMn7p3IjWPbjp1c+aOZrNm4le//zUiauncpO5IkSZIo8OkWmbk9Iq4CJgMdgZszc25EfAmYnpmTgE9FxGhgO7AWGFt5+gXAqcDBEfHKfWMzc/be/THq01d+Po/fP72Wb194PMf171V2HEmSJFVEZpad4VVGjhyZ06dPLztGm7tj2lI+f9ccPvr2gVzreciSJEk1FxEzMnPkrh7zBNgSzHr2Ba796eO8fVCTXxgiSZK0D7Ik19jKDZv5+G0zOKRXF7578Yl08o16kiRJ+5zdnpOsvWfL9h18/LYZbHh5O3dfoBJw4wAACilJREFU8ecc2K1z2ZEkSZK0C5bkGslM/uHeucx8dh3Xf3AEb+nXs+xIkiRJeg3+X3+N3Pb7Z5kwbSlXnn4U5x7Xb/dPkCRJUmksyTXwh6fX8k+T5nL60X0Yd9bRZceRJEnSbliS29iKdS9zxY9mcPhBB/Cdi06kY4coO5IkSZJ2w3OS29DmbTu4/NYZbN62kwmXnUSv/fcrO5IkSZIKsCS3kczk7+5+jMeWr+fGS0YyqG+PsiNJkiSpIE+3aCM3T13C3bOWM+6sIZw17JCy40iSJKkVLMltYOqi1fzLL+dz9jGHcNXpg8qOI0mSpFayJO9lS9du4sofz+TIpm5884IT6OAb9SRJkuqO5yTvJWs3bmXS7OXcPHUJO3cmN14yku5dHK8kSVI9ssW9AVu372TKgpVMnLGM+xesZNuO5Jg39WT8+cMZ0NSt7HiSJEnaQ5bkVspM5q7YwMQZy5j06ArWbtxKU/cuXHryAMac1N+vm5YkSWoAluSCVr64mXtnreCumct44rkX6dyxA+8c1pfzT+rPqYP70Kmjp3dLkiQ1Ckvy69i8bQe/mb+Su2Yu43cLV7FjZ3LCYb358vuO5T3D+9H7gM5lR5QkSVIbsCRXyUxmL13HXTOXMWn2CjZs3s6hPbty2alHMmZEfwb17V52REmSJLUxS3LFH9e/zD2zljNxxjIWr9pIl04dOOfYQxkzoj+nDGqiox/lJkmS1G5YkoEdO5P3fPchVr+0lbcOOJDL/uJIzh3ej55d9ys7miRJkkpgSQY6dgjGn388A5u6+dFtkiRJsiS/4vShfcuOIEmSpH2En1smSZIkVbEkS5IkSVUsyZIkSVIVS7IkSZJUxZIsSZIkVbEkS5IkSVUsyZIkSVIVS7IkSZJUxZIsSZIkVbEkS5IkSVUsyZIkSVIVS7IkSZJUxZIsSZIkVbEkS5IkSVUsyZIkSVIVS7IkSZJUxZIsSZIkVbEkS5IkSVUsyZIkSVIVS7IkSZJUJTKz7AyvEhGrgGdKevkmYHVJr91eOOPacM5tzxnXhnNue864NpxzbbR2zkdkZp9dPbDPleQyRcT0zBxZdo5G5oxrwzm3PWdcG8657Tnj2nDOtbE35+zpFpIkSVIVS7IkSZJUxZL8ajeUHaAdcMa14ZzbnjOuDefc9pxxbTjn2thrc/acZEmSJKmKK8mSJElSlXZZkiPinIhYEBGLIuKaXTw+LiLmRcSciPhNRBxRRs56VmDGH4+IxyJidkQ8FBHDyshZ73Y35xbbjYmIjAjfWd1KBfblsRGxqrIvz46Ij5aRs94V2Zcj4oLKsXluRPy41hnrXYF9+dst9uOFEbGujJz1rsCcD4+I+yNiVqVnnFtGznpWYMZHVPrbnIiYEhH99+iFMrNdXYCOwFPAkUBn4FFgWNU2pwMHVK5/AvhJ2bnr6VJwxj1bXB8N/HfZuevtUmTOle16AA8AjwAjy85dT5eC+/JY4N/KzlrPl4JzHgzMAg6s3O5bdu56uhQ9XrTY/pPAzWXnrrdLwX35BuATlevDgCVl566nS8EZ3wlcWrl+BnDrnrxWe1xJHgUsyszFmbkVmAC8t+UGmXl/Zm6q3HwE2LN/gbRfRWa8ocXNboAnx7febudc8WXga8DmWoZrEEVnrDemyJw/BlyXmS8AZObKGmesd63dly8Gbq9JssZSZM4J9Kxc7wWsqGG+RlBkxsOA31au37+LxwtpjyX5zcDSFreXVe57LR8B/qtNEzWeQjOOiCsj4ing68CnapStkex2zhExAjgsM39Ry2ANpOjxYkzlv/UmRsRhtYnWUIrMeQgwJCKmRsQjEXFOzdI1hsJ/91VOMRzI/5cMFVdkzv8IfCgilgG/pHnVXsUVmfGjwHmV6+8HekTEwa19ofZYkguLiA8BI4HxZWdpRJl5XWYeBXwBuLbsPI0mIjoA3wI+W3aWBvczYEBmDgfuA35Ycp5G1YnmUy5Oo3mV88aI6F1qosZ1ETAxM3eUHaRBXQz8IDP7A+cCt1aO19p7Pge8IyJmAe8AlgOt3p/b4x/KcqDlSk//yn2vEhHvBL4IjM7MLTXK1igKzbiFCcD72jRRY9rdnHsAxwJTImIJ8DZgkm/ea5Xd7suZuabFMeIm4KQaZWskRY4Zy4BJmbktM58GFtJcmlVMa47LF+GpFnuqyJw/AtwBkJkPA12BppqkawxFjssrMvO8zDyR5i5HZrb6jajtsSRPAwZHxMCI6EzzwWBSyw0i4kTg+zQXZM97a70iM275l9tfAU/WMF+jeN05Z+b6zGzKzAGZOYDm8+tHZ+b0cuLWpSL7cr8WN0cD82uYr1Hsds7AT2leRSYimmg+/WJxLUPWuSIzJiKGAgcCD9c4X6MoMudngTMBIuItNJfkVTVNWd+KHJebWqzO/y1w8568ULsryZm5HbgKmEzzX2Z3ZObciPhSRIyubDYe6A7cWfkonD85kOi1FZzxVZWPcZoNjAMuLSlu3So4Z70BBWf8qcq+/CjN59aPLSdt/So458nAmoiYR/Mbca7OzDXlJK4/rTheXARMyMrHAqh1Cs75s8DHKseM24Gxzru4gjM+DVgQEQuBQ4B/3pPX8hv3JEmSpCrtbiVZkiRJ2h1LsiRJklTFkixJkiRVsSRLkiRJVSzJkiRJUhVLsiTVSET0jogrKtdPi4ift8Fr/CAizm/F9gMi4vHXeGyKXz4jqb2yJEtS7fQGrmjNEyKiYxtlkSS9DkuyJNXOV4GjKl+iMx7oHhETI+KJiPhRRARARCyJiK9FxEzgryPiXRHxcETMjIg7I6J7ZbuvRsS8iJgTEd9o8TqnRsT/RMTiV1aVo9n4iHg8Ih6LiAurw0XE/hExISLmR8Q9wP5tPRBJ2ld1KjuAJLUj1wDHZuYJEXEacC9wDLACmAqcAjxU2XZNZo6ofAXz3cA7M3NjRHwBGBcR1wHvB4ZmZkZE7xav0w94OzCU5q9rnQicB5wAHA80AdMi4oGqfJ8ANmXmWyJiODBzL//8klQ3XEmWpPL8ITOXZeZOYDYwoMVjP6n8+jZgGDC1sgJ9KXAEsB7YDPxHRJwHbGrx3J9m5s7MnEfzV7JCc2m+PTN3ZObzwO+At1blORW4DSAz5wBz9s6PKUn1x5VkSSrPlhbXd/DqY/LGyq8B3JeZF1c/OSJGAWcC5wNXAWfs4veNvZZWktoRV5IlqXZeBHq08jmPAKdExCCAiOgWEUMq5yX3ysxfAp+h+TSK1/MgcGFEdIyIPjSvGv+hapsHgA9UXudYYHgrs0pSw3AlWZJqJDPXRMTUykeuvQw8X+A5qyJiLHB7RHSp3H0tzYX73ojoSvNq8bjd/Fb3ACcDjwIJfD4zn4uIAS22+R7wnxExH5gPzCj6s0lSo4nMLDuDJEmStE/xdAtJkiSpiiVZkiRJqmJJliRJkqpYkiVJkqQqlmRJkiSpiiVZkiRJqmJJliRJkqpYkiVJkqQq/wvMPC8tQQ+Z3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sprint20 models_pretrained_and_more.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
